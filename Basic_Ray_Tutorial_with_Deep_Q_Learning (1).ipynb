{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Ray Tutorial and Deep Q Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of the tutorial we showcase what ray can do to speed up code and functions.  We will show how a simple decorator function enables a standard written python function to be run in a parallelized manner and distributed across nodes.\n",
    "\n",
    "The second part of this tutorial focuses on the cart-pole problem. A cart has a pole fixed with a movable lever in the middle of the cart. The cart slides along a frictionless surface. The goal is to keep the pole upright at all times. The test is how far back and forth the cart can move in order to prevent the pole from falling. The tutorial has been modified heavily so that it (i) runs in a jupyter notebook, (ii) demonstrates full capabilities of ray, and ray tune and (iii) breaks down the components of a RL project along with enhanced explainations of the code. We may modify this tutorial further to solve a different problem.\n",
    "\n",
    "In the third part of the tutorial, we demonstrate how to create a custom reinforcement learning environment with the problem space of a robot walking down a corridor.\n",
    "\n",
    "#### References:\n",
    "\n",
    "Barto, A. G., Sutton, R. S. and Anderson, C. (1983), ‘Neuron-like adaptive elements that can solve difficult learning control problems’, IEEE Transactions on Systems, 5, Man, and Cybernetics 13, 834–846\n",
    "\n",
    "Tune: A Research Platform for Distributed Model Selection and Training, Liaw, Richard and Liang, Eric and Nishihara, Robert and Moritz, Philipp and Gonzalez, Joseph E and Stoica, Ion, arXiv preprint arXiv:1807.05118}, 2018\n",
    "\n",
    "Ray RLLib Documentation: [Ray RLLib Documentation](https://docs.ray.io/en/latest/rllib-training.html#getting-started)\n",
    "\n",
    "Ray Tune Documentation: [Ray Tune Documentation](https://docs.ray.io/en/latest/tune/index.html)\n",
    "\n",
    "Mastering Reinforcement Learning with Python, Enes Bilgin, Packt Publishing, 2020 [Buy MRL with Python](https://www.amazon.com/Mastering-Reinforcement-Learning-Python-next-generation/dp/1838644148/?tag=meastus-200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Ray Version, Instantiating Ray Instances and Looking at Node Parameters\n",
    "\n",
    "Its typically helpful to check the parameters for nodes to ensure that they are in good shape.  One can also navigate to the tab which says 'Ray Web UI) to look through the node pool and ray actors as well as memory.  These are advanced topics and are meant for trouble-shooting only. \n",
    "\n",
    "\n",
    "In this notebook we'll start with showing you how easy it is to use Ray to convert regular functions into ones that are parallelized and distributed across nodes.  Before we do anything though, let's check our version of Ray.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ray, version 1.9.0\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! ray --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import os\n",
    "\n",
    "if ray.is_initialized() == False:\n",
    "   service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "   service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "   #_temp_dir='/domino/datasets/local/{}/'.format(os.environ['DOMINO_PROJECT_NAME']) #set to a dataset\n",
    "   ray.util.connect(f\"{service_host}:{service_port}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the health of the nodes, look at their CPU and GPU per node.  Here you can see each node, including the head node have seven GPUs (this may differ in your example depending on your environment).  It's a good idea to check this and plan for memory usuage with Ray.  If there isn't enough memory overhead for the code as written, a data channel error will shutdown.  There are advanced techniques to prevent this.  This happens regardless of the verison of Ray used, so make sure to check each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'NodeID': '3e29ea829a1a9c7cc62058de0cdfdc10e5e4a03ee540964e29b4be92',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '10.0.37.253',\n",
       "  'NodeManagerHostname': 'ray-61bf4c91992e0d71a81ef1b3-ray-worker-1',\n",
       "  'NodeManagerPort': 2385,\n",
       "  'ObjectManagerPort': 2384,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2021-12-19_15-25-31_965372_1/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2021-12-19_15-25-31_965372_1/sockets/raylet',\n",
       "  'MetricsExportPort': 55975,\n",
       "  'alive': True,\n",
       "  'Resources': {'memory': 41296069428.0,\n",
       "   'CPU': 7.0,\n",
       "   'GPU': 1.0,\n",
       "   'object_store_memory': 17698315468.0,\n",
       "   'node:10.0.37.253': 1.0,\n",
       "   'accelerator_type:V100': 1.0}},\n",
       " {'NodeID': '8671482a0e1a13d793effbe70ee2709b8d3c5793e1bcf4b89b1554d7',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '10.0.60.5',\n",
       "  'NodeManagerHostname': 'ray-61bf4c91992e0d71a81ef1b3-ray-worker-0',\n",
       "  'NodeManagerPort': 2385,\n",
       "  'ObjectManagerPort': 2384,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2021-12-19_15-25-31_965372_1/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2021-12-19_15-25-31_965372_1/sockets/raylet',\n",
       "  'MetricsExportPort': 53997,\n",
       "  'alive': True,\n",
       "  'Resources': {'accelerator_type:V100': 1.0,\n",
       "   'object_store_memory': 17698736947.0,\n",
       "   'node:10.0.60.5': 1.0,\n",
       "   'GPU': 1.0,\n",
       "   'CPU': 7.0,\n",
       "   'memory': 41297052877.0}},\n",
       " {'NodeID': 'f9aa63e1ee3c5e06a6f5dd275f55cb8afb2c4fe188bee9aa0b712b76',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '10.0.49.194',\n",
       "  'NodeManagerHostname': 'ray-61bf4c91992e0d71a81ef1b3-ray-worker-2',\n",
       "  'NodeManagerPort': 2385,\n",
       "  'ObjectManagerPort': 2384,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2021-12-19_15-25-31_965372_1/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2021-12-19_15-25-31_965372_1/sockets/raylet',\n",
       "  'MetricsExportPort': 57906,\n",
       "  'alive': True,\n",
       "  'Resources': {'accelerator_type:V100': 1.0,\n",
       "   'node:10.0.49.194': 1.0,\n",
       "   'memory': 41296958260.0,\n",
       "   'CPU': 7.0,\n",
       "   'object_store_memory': 17698696396.0,\n",
       "   'GPU': 1.0}},\n",
       " {'NodeID': 'b4fe161a0614bac87e232d303cebf96617ca1a2b232686671b4fe599',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '10.0.51.106',\n",
       "  'NodeManagerHostname': 'ray-61bf4c91992e0d71a81ef1b3-ray-head-0',\n",
       "  'NodeManagerPort': 2385,\n",
       "  'ObjectManagerPort': 2384,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2021-12-19_15-25-31_965372_1/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2021-12-19_15-25-31_965372_1/sockets/raylet',\n",
       "  'MetricsExportPort': 40943,\n",
       "  'alive': True,\n",
       "  'Resources': {'memory': 35397392795.0,\n",
       "   'GPU': 1.0,\n",
       "   'CPU': 7.0,\n",
       "   'node:10.0.51.106': 1.0,\n",
       "   'accelerator_type:V100': 1.0,\n",
       "   'object_store_memory': 17698696396.0}},\n",
       " {'NodeID': '0a575df75ab908eea41377086b0559c5260cc90dc8b92fd33bb746fd',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '10.0.41.148',\n",
       "  'NodeManagerHostname': 'ray-61bf4c91992e0d71a81ef1b3-ray-worker-3',\n",
       "  'NodeManagerPort': 2385,\n",
       "  'ObjectManagerPort': 2384,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2021-12-19_15-25-31_965372_1/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2021-12-19_15-25-31_965372_1/sockets/raylet',\n",
       "  'MetricsExportPort': 65453,\n",
       "  'alive': True,\n",
       "  'Resources': {'node:10.0.41.148': 1.0,\n",
       "   'memory': 41297110221.0,\n",
       "   'CPU': 7.0,\n",
       "   'GPU': 1.0,\n",
       "   'accelerator_type:V100': 1.0,\n",
       "   'object_store_memory': 17698761523.0}}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Ray and what can it do?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ray is a flexible distributed computing system available on Domino product on demand.  With Ray one can run code both in parallel or in distributed mode.  Parallel mode refers to running a function on several threads simultaneously in parallel.  This method can also be accomplished on multiple nodes at once (distributed computing).  One will notice that the wall clock time (which we compute below) differs from the compute time.  With multiple nodes or threading (running in a distributed fashion), the compute time is split among nodes.  Thus when we provide a 10 second 'sleep' we can see that the 10 seconds is distributed and so the wall clock time (the time we actually experience) is shorter than compute time.  This is part of the magic of parallel and distributed computing.  Let's take a closer look below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "Time taken:  10.008283853530884\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import ray\n",
    "\n",
    "\n",
    "y = 1\n",
    "object_ref = y\n",
    "\n",
    "def add(x, a=1):\n",
    "    if x == 'add':\n",
    "        answer = a + 1\n",
    "    else:\n",
    "        answer = a\n",
    "    time.sleep(5)\n",
    "    print(answer)\n",
    "    \n",
    "number_add =add('add')\n",
    "number_none =add('hello')\n",
    "        \n",
    "object_ids = []\n",
    "st = time.time()\n",
    "for x in range(2):\n",
    "    x = x\n",
    "    y_id = add('add')\n",
    "    object_ids.append(y_id) # the object ids will print out\n",
    "    \n",
    "## getting the results to pass to another function\n",
    "objects = object_ids\n",
    "end = time.time()\n",
    "print(\"Time taken: \", str(end-st))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating remote objects\n",
    "\n",
    "Put an object in Ray's object store, get it out and run the function\n",
    "say want to add 10 million and after every million 5 seconds, total processing would be 50 seconds\n",
    "\n",
    "Do this in ray, and have 3 ray workers, adding 1 million values each, \n",
    "after calculating 1 million each sleeps 5 seconds, then total processing takes less than six seconds\n",
    "iterations in learning \n",
    "ml is already iterative, running partitions on each worker and at the distributed sequentially now paralellized\n",
    "call without ray and then with ray\n",
    "small amount of data, run and then kick off with same code but a larger data set, locally and in cloud testuse 10 workers, each sleeps 2 seconds, and see the difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(add pid=220)\u001b[0m 2\n",
      "\u001b[2m\u001b[36m(add pid=220)\u001b[0m 1\n",
      "5.057931423187256\n",
      "\u001b[2m\u001b[36m(add pid=220)\u001b[0m 2\n",
      "\u001b[2m\u001b[36m(add pid=218)\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import time\n",
    "\n",
    "y = 1\n",
    "object_ref = ray.put(y)\n",
    "\n",
    "@ray.remote\n",
    "def add(x, a=1):\n",
    "    if x == 'add':\n",
    "        answer = a + 1\n",
    "    else:\n",
    "        answer = a\n",
    "    time.sleep(5)\n",
    "    print(answer)\n",
    "    \n",
    "number_add = ray.get(add.remote('add'))\n",
    "number_none = ray.get(add.remote('hello'))\n",
    "        \n",
    "object_ids = []\n",
    "st = time.time()\n",
    "for x in range(2):\n",
    "    x = x\n",
    "    y_id = add.remote('add')\n",
    "    object_ids.append(y_id) # the object ids will print out\n",
    "    \n",
    "## getting the results to pass to another function\n",
    "objects = ray.get(object_ids)\n",
    "end = time.time()\n",
    "print(str(end-st))\n",
    "\n",
    "#notice that the process ids (pid) have the same number (223) except for the head node which has the number 221"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximations of Pi, using n>50\n",
    "\n",
    "def pi(n):\n",
    "    if n >= 50:\n",
    "        k = 1\n",
    "        # Initialize sum\n",
    "        s = 0\n",
    "        for i in range(n):\n",
    "            # even index elements are positive\n",
    "            if i % 2 == 0:\n",
    "                s += 4/k\n",
    "            else:\n",
    "                # odd index elements are negative\n",
    "                s -= 4/k\n",
    "            # if denominator is odd\n",
    "            k += 2\n",
    "        time.sleep(10)    \n",
    "        print(s)\n",
    "    else:\n",
    "        print('Try a number greater than or equal to 50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1415916535897743\n",
      "CPU times: user 185 ms, sys: 0 ns, total: 185 ms\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pi(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def pi(n):\n",
    "    if n >= 50:\n",
    "        k = 1\n",
    "        # Initialize sum\n",
    "        s = 0\n",
    "        for i in range(n):\n",
    "            # even index elements are positive\n",
    "            if i % 2 == 0:\n",
    "                s += 4/k\n",
    "            else:\n",
    "                # odd index elements are negative\n",
    "                s -= 4/k\n",
    "            # if denominator is odd\n",
    "            k += 2\n",
    "        time.sleep(10)\n",
    "        print(s)\n",
    "    else:\n",
    "        print('Try a number greater than or equal to 50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.7 ms, sys: 0 ns, total: 3.7 ms\n",
      "Wall time: 3.24 ms\n",
      "\u001b[2m\u001b[36m(pi pid=220)\u001b[0m 3.1415916535897743\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pi = pi.remote(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the above examples the compute time differs and the wall clock time for the compute differs. However keep in mind Ray is only using one worker to calculate pi in this simple example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few more examples below show how to appropriately use Ray to speed up calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pi pid=220)\u001b[0m 3.1415916535897743\n",
      "1 2 3\n",
      "The wall-clock time is  5.005219459533691\n"
     ]
    }
   ],
   "source": [
    "def return_multiple():\n",
    "    time.sleep(5)\n",
    "    return 1, 2, 3\n",
    "\n",
    "st = time.time()\n",
    "a, b, c = return_multiple()\n",
    "end = time.time()\n",
    "print(a,b,c)\n",
    "print('The wall-clock time is ', str(end-st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n",
      "The wall-clock time is  0.004021167755126953\n"
     ]
    }
   ],
   "source": [
    "@ray.remote(num_returns=3)\n",
    "def return_multiple():\n",
    "    time.sleep(5)\n",
    "    return 1, 2, 3\n",
    "\n",
    "\n",
    "st = time.time()\n",
    "a, b, c = return_multiple.remote()\n",
    "end = time.time()\n",
    "print(ray.get(a), ray.get(b), ray.get(c))\n",
    "print('The wall-clock time is ', str(end-st))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Cart Pole Problem\n",
    "\n",
    "Training with hyperparameter tuning was traditionally very human-time intensive. With the Ray 'tune' tool, hyper-parameter tuning is automated.  Ray is not the only software that can do this neat trick of parallel and distributed compute.  It can be done with any distributed system.  Ray just happens to particularlly excell at deeep learning and reinforcement learning.  \n",
    "\n",
    "RLlib is an open-source library for reinforcement learning that offers both high scalability and a unified API for a variety of applications. RLlib natively supports TensorFlow, TensorFlow Eager, and PyTorch, but most of its internals are framework agnostic. See the docs [here](https://docs.ray.io/en/latest/rllib.html) for more information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Cart-Pole Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining the best learning rate using Ray's Tune library\n",
    "\n",
    "The example below shows how to use Ray's Tune library with the cart-pole problem.  The best learning rate can be determined by the reward amount.  Its a best practise to shutdown and re start your distributed computing system each time.  This allows the workers to clear their memory.  In addition the example below is one where we run the cart-pole problem in a distributed manner.  We'll show a second example where we run the experiment in a parallel manner.  In this distributed example you'll see that it takes less than 20 seconds to run the entire training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import os\n",
    "\n",
    "ray.shutdown()\n",
    "\n",
    "if ray.is_initialized() == False:\n",
    "   service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "   service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "   _temp_dir='/domino/datasets/local/{}/'.format(os.environ['DOMINO_PROJECT_NAME']) #set to a dataset\n",
    "   ray.util.connect(f\"{service_host}:{service_port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Current time: 2021-12-19 15:29:10 (running for 00:00:00.13)\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Memory usage on this node: 3.4/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Resources requested: 0/35 CPUs, 0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Result logdir: /home/ubuntu/ray_results/DQN\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Number of trials: 3/3 (3 PENDING)\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m +-----------------------------+----------+-------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | Trial name                  | status   | loc   |     lr |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m |-----------------------------+----------+-------+--------|\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | DQN_CartPole-v0_672ee_00000 | PENDING  |       | 0.01   |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | DQN_CartPole-v0_672ee_00001 | PENDING  |       | 0.001  |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | DQN_CartPole-v0_672ee_00002 | PENDING  |       | 0.0001 |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m +-----------------------------+----------+-------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=367)\u001b[0m 2021-12-19 15:29:13,712\tINFO trainer.py:722 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also want to then set `eager_tracing=True` in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(DQN pid=367)\u001b[0m 2021-12-19 15:29:13,712\tINFO dqn.py:141 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=367)\u001b[0m 2021-12-19 15:29:13,712\tINFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=77, ip=10.0.49.194)\u001b[0m 2021-12-19 15:29:15,042\tINFO trainer.py:722 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also want to then set `eager_tracing=True` in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(DQN pid=77, ip=10.0.49.194)\u001b[0m 2021-12-19 15:29:15,042\tINFO dqn.py:141 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=77, ip=10.0.49.194)\u001b[0m 2021-12-19 15:29:15,042\tINFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=77, ip=10.0.41.148)\u001b[0m 2021-12-19 15:29:15,116\tINFO trainer.py:722 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also want to then set `eager_tracing=True` in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(DQN pid=77, ip=10.0.41.148)\u001b[0m 2021-12-19 15:29:15,117\tINFO dqn.py:141 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=77, ip=10.0.41.148)\u001b[0m 2021-12-19 15:29:15,117\tINFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=540)\u001b[0m 2021-12-19 15:29:18,848\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76, ip=10.0.49.194)\u001b[0m 2021-12-19 15:29:18,901\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=76, ip=10.0.41.148)\u001b[0m 2021-12-19 15:29:19,156\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=77, ip=10.0.49.194)\u001b[0m 2021-12-19 15:29:20,583\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=367)\u001b[0m 2021-12-19 15:29:20,641\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=77, ip=10.0.41.148)\u001b[0m 2021-12-19 15:29:20,996\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Current time: 2021-12-19 15:29:22 (running for 00:00:12.05)\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Memory usage on this node: 4.1/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Resources requested: 6.0/35 CPUs, 0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Result logdir: /home/ubuntu/ray_results/DQN\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Number of trials: 3/3 (3 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m +-----------------------------+----------+-----------------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | Trial name                  | status   | loc             |     lr |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m |-----------------------------+----------+-----------------+--------|\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | DQN_CartPole-v0_672ee_00000 | RUNNING  | 10.0.51.106:367 | 0.01   |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | DQN_CartPole-v0_672ee_00001 | RUNNING  | 10.0.49.194:77  | 0.001  |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | DQN_CartPole-v0_672ee_00002 | RUNNING  | 10.0.41.148:77  | 0.0001 |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m +-----------------------------+----------+-----------------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Current time: 2021-12-19 15:29:23 (running for 00:00:13.06)\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Memory usage on this node: 4.1/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Resources requested: 6.0/35 CPUs, 0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Result logdir: /home/ubuntu/ray_results/DQN\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Number of trials: 3/3 (3 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m +-----------------------------+----------+-----------------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | Trial name                  | status   | loc             |     lr |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m |-----------------------------+----------+-----------------+--------|\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | DQN_CartPole-v0_672ee_00000 | RUNNING  | 10.0.51.106:367 | 0.01   |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | DQN_CartPole-v0_672ee_00001 | RUNNING  | 10.0.49.194:77  | 0.001  |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | DQN_CartPole-v0_672ee_00002 | RUNNING  | 10.0.41.148:77  | 0.0001 |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m +-----------------------------+----------+-----------------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Result for DQN_CartPole-v0_672ee_00001:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   agent_timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   date: 2021-12-19_15-29-23\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_len_mean: 22.568181818181817\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_reward_max: 54.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_reward_mean: 22.568181818181817\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_reward_min: 9.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episodes_this_iter: 44\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episodes_total: 44\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   experiment_id: bdcafa37db6348ce86024512d82e9726\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-2\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     last_target_update_ts: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           cur_lr: 0.0010000000474974513\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           max_q: 0.9748879075050354\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           mean_q: 0.18523329496383667\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           mean_td_error: -0.8953237533569336\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           min_q: -0.250682532787323\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           model: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.9018473625183105\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.2245506048202515\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.6029106974601746\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.1425418257713318\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.6173948049545288\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.0513391494750977\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.544265627861023\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.8906919360160828\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.04918462038040161\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.2688732147216797\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.160576343536377\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.5596193075180054\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.8637595176696777\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.584993600845337\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.8338418006896973\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.921478807926178\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.9098070859909058\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.160576343536377\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.2538337707519531\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.3376350402832031\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.6385536193847656\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.3878015279769897\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.7413718700408936\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.4191003441810608\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.8409696817398071\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.90301913022995\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.7218947410583496\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.4040286540985107\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.2688732147216797\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.6296179294586182\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.3878012895584106\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.4276044368743896\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_agent_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_agent_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_target_updates: 1\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   node_ip: 10.0.49.194\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   num_healthy_workers: 1\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     cpu_util_percent: 14.899999999999999\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     gpu_util_percent0: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     ram_util_percent: 5.675\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     vram_util_percent0: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   pid: 77\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_action_processing_ms: 0.07541291601769813\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_env_wait_ms: 0.07489868453689867\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_inference_ms: 1.1564330025748175\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_raw_obs_processing_ms: 0.16810105635331468\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   time_since_restore: 2.3801772594451904\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   time_this_iter_s: 2.3801772594451904\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   time_total_s: 2.3801772594451904\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     learn_throughput: 142.22\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     learn_time_ms: 225.004\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     load_throughput: 109297.824\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     load_time_ms: 0.293\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     update_time_ms: 4.871\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timestamp: 1639927763\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   trial_id: 672ee_00001\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Result for DQN_CartPole-v0_672ee_00000:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   agent_timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   date: 2021-12-19_15-29-24\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_len_mean: 19.21153846153846\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_reward_max: 56.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_reward_mean: 19.21153846153846\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_reward_min: 9.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episodes_this_iter: 52\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episodes_total: 52\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   experiment_id: f4867aaaa69a4935a25a708292af5666\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-head-0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     last_target_update_ts: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           cur_lr: 0.009999999776482582\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           max_q: 0.25147730112075806\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           mean_q: -0.03314869478344917\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           mean_td_error: -0.7205875515937805\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           min_q: -0.6453880667686462\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           model: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - 0.2709965109825134\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - 0.11048632860183716\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.35498127341270447\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.9728803038597107\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.5564123392105103\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.8699647784233093\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.2006332874298096\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.0854299068450928\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.8613623380661011\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.5128684639930725\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.7930105328559875\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.9622378349304199\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.2159507274627686\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.8972753882408142\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - 0.02340865135192871\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.8529375195503235\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.9915743470191956\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.6257864832878113\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.3707621097564697\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.7983299493789673\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.7106232643127441\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.6320685744285583\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.38151633739471436\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.46043074131011963\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.2110925167798996\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.8432136178016663\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.29034629464149475\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.8582439422607422\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.5036084651947021\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.8498711585998535\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.9470009803771973\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.8532810807228088\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_agent_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_agent_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_target_updates: 1\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   node_ip: 10.0.51.106\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   num_healthy_workers: 1\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     cpu_util_percent: 16.6\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     gpu_util_percent0: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     ram_util_percent: 6.8\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     vram_util_percent0: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   pid: 367\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_action_processing_ms: 0.07788975398380917\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_env_wait_ms: 0.07843709254002833\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_inference_ms: 1.2117608801111002\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_raw_obs_processing_ms: 0.17720407301133922\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   time_since_restore: 2.494781732559204\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   time_this_iter_s: 2.494781732559204\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   time_total_s: 2.494781732559204\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     learn_throughput: 126.646\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     learn_time_ms: 252.674\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     load_throughput: 68759.082\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     load_time_ms: 0.465\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     update_time_ms: 5.156\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timestamp: 1639927764\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   trial_id: 672ee_00000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Result for DQN_CartPole-v0_672ee_00002:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   agent_timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   date: 2021-12-19_15-29-24\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_len_mean: 21.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_reward_max: 48.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_reward_mean: 21.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episode_reward_min: 11.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episodes_this_iter: 47\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   episodes_total: 47\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   experiment_id: 8962603620584e2bae3e2b69b36e3bad\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-3\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     last_target_update_ts: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           cur_lr: 9.999999747378752e-05\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           max_q: 0.7482873201370239\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           mean_q: -0.010050836950540543\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           mean_td_error: -0.9760867357254028\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           min_q: -0.5770772099494934\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m           model: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.1582337617874146\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.6873146295547485\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.5114012956619263\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.8105530738830566\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.5213940143585205\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.43106862902641296\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.0036985874176025\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.1788511276245117\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.0598729848861694\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.4388481378555298\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.8178194165229797\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - 0.09279084205627441\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.628471851348877\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.9407601356506348\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.593485713005066\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.1061359643936157\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.7661580443382263\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.5949409008026123\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.249649167060852\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.5272438526153564\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.7927339673042297\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.1425288915634155\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.9265794157981873\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.9981175661087036\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.8811201453208923\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.6749637126922607\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.1992619037628174\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.7033814191818237\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.7852510213851929\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.9182761311531067\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -1.4806702136993408\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m         - -0.7987799048423767\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_agent_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_agent_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     num_target_updates: 1\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   node_ip: 10.0.41.148\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   num_healthy_workers: 1\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     cpu_util_percent: 16.425\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     gpu_util_percent0: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     ram_util_percent: 5.675\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     vram_util_percent0: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   pid: 77\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_action_processing_ms: 0.08113615281812914\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_env_wait_ms: 0.07670552104145853\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_inference_ms: 1.183674171135261\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     mean_raw_obs_processing_ms: 0.17148131257170562\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   time_since_restore: 2.4572126865386963\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   time_this_iter_s: 2.4572126865386963\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   time_total_s: 2.4572126865386963\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     learn_throughput: 132.701\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     learn_time_ms: 241.143\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     load_throughput: 108590.395\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     load_time_ms: 0.295\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m     update_time_ms: 5.201\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timestamp: 1639927764\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   trial_id: 672ee_00002\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Current time: 2021-12-19 15:29:24 (running for 00:00:14.60)\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Memory usage on this node: 3.4/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Resources requested: 0/35 CPUs, 0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Result logdir: /home/ubuntu/ray_results/DQN\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m Number of trials: 3/3 (3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m +-----------------------------+------------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | Trial name                  | status     | loc             |     lr |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m |-----------------------------+------------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | DQN_CartPole-v0_672ee_00000 | TERMINATED | 10.0.51.106:367 | 0.01   |      1 |          2.49478 | 1000 |  19.2115 |                   56 |                    9 |            19.2115 |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | DQN_CartPole-v0_672ee_00001 | TERMINATED | 10.0.49.194:77  | 0.001  |      1 |          2.38018 | 1000 |  22.5682 |                   54 |                    9 |            22.5682 |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m | DQN_CartPole-v0_672ee_00002 | TERMINATED | 10.0.41.148:77  | 0.0001 |      1 |          2.45721 | 1000 |  21      |                   48 |                   11 |            21      |\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m +-----------------------------+------------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=370)\u001b[0m 2021-12-19 15:29:25,057\tINFO tune.py:626 -- Total run time: 18.90 seconds (14.55 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "\n",
    "analysis = tune.run(\n",
    "    \"DQN\",\n",
    "    stop={\"episode_reward_mean\": 1},\n",
    "    config={\n",
    "        \"env\": \"CartPole-v0\",\n",
    "        \"num_gpus\": 0,\n",
    "        \"num_workers\": 1,\n",
    "        \"lr\": tune.grid_search([0.01, 0.001, 0.0001]),\n",
    "    },\n",
    ")\n",
    "\n",
    "#print(\"Best configuration: \", analysis.best_config)\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looping through multiple iterations to find the best policy\n",
    "\n",
    "In this example we see that a single node can perform the training.  It takes less than a minute to finish the training loop.  After the data is collected from the training iterations (10), we can look at the results to determine the maximum, mean and minimum reward.  We graph that.  For this notebook you can choose which log files you would like to see using the input.  See what your results look like!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-19 15:59:20,278\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.0.47.10',\n",
       " 'raylet_ip_address': '10.0.47.10',\n",
       " 'redis_address': '10.0.47.10:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-12-19_15-59-17_714742_239/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-12-19_15-59-17_714742_239/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-12-19_15-59-17_714742_239',\n",
       " 'metrics_export_port': 42266,\n",
       " 'node_id': '1db3b3625f6624d581aeef8352feaef958bf06c4a2f1e4f9ba010ea6'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=8404)\u001b[0m 2021-12-19 15:59:26,755\tWARNING deprecation.py:45 -- DeprecationWarning: `SampleBatch['is_training']` has been deprecated. Use `SampleBatch.is_training` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 1000\n",
      "custom_metrics: {}\n",
      "date: 2021-12-19_15-59-32\n",
      "done: false\n",
      "episode_len_mean: 22.674418604651162\n",
      "episode_media: {}\n",
      "episode_reward_max: 78.0\n",
      "episode_reward_mean: 22.674418604651162\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 43\n",
      "episodes_total: 43\n",
      "experiment_id: e4b7e5fff46b45788ed74b177b87c05c\n",
      "hostname: run-61bf4c91992e0d71a81ef1b3-46bg7\n",
      "info:\n",
      "  last_target_update_ts: 1000\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 0.6478759050369263\n",
      "        mean_q: -0.057972364127635956\n",
      "        mean_td_error: -0.9809002876281738\n",
      "        min_q: -0.6995514631271362\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - -0.8978910446166992\n",
      "      - -0.8127206563949585\n",
      "      - -1.467315912246704\n",
      "      - -1.2674442529678345\n",
      "      - -0.9970976710319519\n",
      "      - -0.4226508140563965\n",
      "      - -1.0998400449752808\n",
      "      - -1.042556643486023\n",
      "      - -0.1850542426109314\n",
      "      - -0.7924472093582153\n",
      "      - -0.8127206563949585\n",
      "      - -0.6119676828384399\n",
      "      - -1.2850316762924194\n",
      "      - -1.0044187307357788\n",
      "      - -0.9896682500839233\n",
      "      - -0.8772618770599365\n",
      "      - -0.746869683265686\n",
      "      - -0.9747592210769653\n",
      "      - -0.8726824522018433\n",
      "      - -1.1585099697113037\n",
      "      - -0.82053142786026\n",
      "      - -1.0633511543273926\n",
      "      - -1.6995514631271362\n",
      "      - -0.8569310307502747\n",
      "      - -0.9785680174827576\n",
      "      - -0.9329970479011536\n",
      "      - -0.8000106811523438\n",
      "      - -1.193666934967041\n",
      "      - -1.0994421243667603\n",
      "      - -1.3990249633789062\n",
      "      - -1.2007603645324707\n",
      "      - -1.0250649452209473\n",
      "  num_agent_steps_sampled: 1000\n",
      "  num_agent_steps_trained: 32\n",
      "  num_steps_sampled: 1000\n",
      "  num_steps_trained: 32\n",
      "  num_target_updates: 1\n",
      "iterations_since_restore: 1\n",
      "node_ip: 10.0.47.10\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 15.825\n",
      "  gpu_util_percent0: 0.0\n",
      "  ram_util_percent: 7.8\n",
      "  vram_util_percent0: 0.018997524752475247\n",
      "pid: 239\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07713043487274444\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07899848373977096\n",
      "  mean_inference_ms: 1.1987336032040472\n",
      "  mean_raw_obs_processing_ms: 0.1724959610701798\n",
      "time_since_restore: 2.5884337425231934\n",
      "time_this_iter_s: 2.5884337425231934\n",
      "time_total_s: 2.5884337425231934\n",
      "timers:\n",
      "  learn_throughput: 118.104\n",
      "  learn_time_ms: 270.948\n",
      "  load_throughput: 114422.616\n",
      "  load_time_ms: 0.28\n",
      "  update_time_ms: 4.875\n",
      "timestamp: 1639929572\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 1000\n",
      "training_iteration: 1\n",
      "trial_id: default\n",
      "\n",
      "checkpoint saved at /home/ubuntu/ray_results/DQN_CartPole-v0_2021-12-19_15-59-22jrwce5hd/checkpoint_000001/checkpoint-1\n",
      "agent_timesteps_total: 2000\n",
      "custom_metrics: {}\n",
      "date: 2021-12-19_15-59-38\n",
      "done: false\n",
      "episode_len_mean: 22.033333333333335\n",
      "episode_media: {}\n",
      "episode_reward_max: 78.0\n",
      "episode_reward_mean: 22.033333333333335\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 47\n",
      "episodes_total: 90\n",
      "experiment_id: e4b7e5fff46b45788ed74b177b87c05c\n",
      "hostname: run-61bf4c91992e0d71a81ef1b3-46bg7\n",
      "info:\n",
      "  last_target_update_ts: 1504\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 2.4976913928985596\n",
      "        mean_q: 2.006685495376587\n",
      "        mean_td_error: -0.01317712664604187\n",
      "        min_q: 1.576454520225525\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - -0.056482791900634766\n",
      "      - -0.059166669845581055\n",
      "      - -0.21403837203979492\n",
      "      - -0.09243965148925781\n",
      "      - -0.7102205753326416\n",
      "      - -0.04746222496032715\n",
      "      - -0.255634069442749\n",
      "      - 0.6475763320922852\n",
      "      - -0.19222259521484375\n",
      "      - -0.20698130130767822\n",
      "      - -0.46637630462646484\n",
      "      - -0.02495741844177246\n",
      "      - -0.3405160903930664\n",
      "      - 0.880740761756897\n",
      "      - -0.1257394552230835\n",
      "      - 0.27968621253967285\n",
      "      - -0.14893591403961182\n",
      "      - -0.08859944343566895\n",
      "      - -0.5047765970230103\n",
      "      - 0.8092433214187622\n",
      "      - 0.05857372283935547\n",
      "      - -0.12600624561309814\n",
      "      - -0.48804736137390137\n",
      "      - 0.07549834251403809\n",
      "      - -0.5235872268676758\n",
      "      - 1.024677038192749\n",
      "      - -0.17483806610107422\n",
      "      - -0.1150217056274414\n",
      "      - -0.18097639083862305\n",
      "      - 0.734433650970459\n",
      "      - -0.8228079080581665\n",
      "      - 1.0337367057800293\n",
      "  num_agent_steps_sampled: 2000\n",
      "  num_agent_steps_trained: 8032\n",
      "  num_steps_sampled: 2000\n",
      "  num_steps_trained: 8032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 2\n",
      "iterations_since_restore: 2\n",
      "node_ip: 10.0.47.10\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.05\n",
      "  gpu_util_percent0: 0.0\n",
      "  ram_util_percent: 7.8875\n",
      "  vram_util_percent0: 0.018997524752475247\n",
      "pid: 239\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0768804559899673\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07899203396957848\n",
      "  mean_inference_ms: 1.1877476911735514\n",
      "  mean_raw_obs_processing_ms: 0.17314603201548454\n",
      "time_since_restore: 8.520110607147217\n",
      "time_this_iter_s: 5.931676864624023\n",
      "time_total_s: 8.520110607147217\n",
      "timers:\n",
      "  learn_throughput: 8741.548\n",
      "  learn_time_ms: 3.661\n",
      "  load_throughput: 131560.212\n",
      "  load_time_ms: 0.243\n",
      "  update_time_ms: 2.433\n",
      "timestamp: 1639929578\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 2000\n",
      "training_iteration: 2\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 3000\n",
      "custom_metrics: {}\n",
      "date: 2021-12-19_15-59-44\n",
      "done: false\n",
      "episode_len_mean: 21.14\n",
      "episode_media: {}\n",
      "episode_reward_max: 72.0\n",
      "episode_reward_mean: 21.14\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 46\n",
      "episodes_total: 136\n",
      "experiment_id: e4b7e5fff46b45788ed74b177b87c05c\n",
      "hostname: run-61bf4c91992e0d71a81ef1b3-46bg7\n",
      "info:\n",
      "  last_target_update_ts: 2512\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 4.478926658630371\n",
      "        mean_q: 3.7991862297058105\n",
      "        mean_td_error: 0.11823684722185135\n",
      "        min_q: 2.4769718647003174\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - -0.1882014274597168\n",
      "      - 0.6111609935760498\n",
      "      - -0.5029761791229248\n",
      "      - 0.08017230033874512\n",
      "      - 0.04530000686645508\n",
      "      - 0.03146028518676758\n",
      "      - 0.05138874053955078\n",
      "      - -0.0022597312927246094\n",
      "      - 0.06387209892272949\n",
      "      - 0.032774925231933594\n",
      "      - -0.43364405632019043\n",
      "      - -0.06479144096374512\n",
      "      - 0.1753082275390625\n",
      "      - -0.03404855728149414\n",
      "      - 0.2505679130554199\n",
      "      - -0.6269702911376953\n",
      "      - -0.499758243560791\n",
      "      - 1.4769718647003174\n",
      "      - -0.3297286033630371\n",
      "      - 0.048340797424316406\n",
      "      - 0.0026612281799316406\n",
      "      - 0.10475635528564453\n",
      "      - -0.2664759159088135\n",
      "      - 0.0806884765625\n",
      "      - 0.1491866111755371\n",
      "      - -0.4730665683746338\n",
      "      - 1.9147863388061523\n",
      "      - 2.329324245452881\n",
      "      - -0.07943582534790039\n",
      "      - -0.13004350662231445\n",
      "      - 0.091766357421875\n",
      "      - -0.12550830841064453\n",
      "  num_agent_steps_sampled: 3000\n",
      "  num_agent_steps_trained: 16032\n",
      "  num_steps_sampled: 3000\n",
      "  num_steps_trained: 16032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 4\n",
      "iterations_since_restore: 3\n",
      "node_ip: 10.0.47.10\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.7875\n",
      "  gpu_util_percent0: 0.0\n",
      "  ram_util_percent: 7.9\n",
      "  vram_util_percent0: 0.018997524752475247\n",
      "pid: 239\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07659573279592022\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07903750864376624\n",
      "  mean_inference_ms: 1.1756087112398614\n",
      "  mean_raw_obs_processing_ms: 0.17362598897336384\n",
      "time_since_restore: 14.46370530128479\n",
      "time_this_iter_s: 5.943594694137573\n",
      "time_total_s: 14.46370530128479\n",
      "timers:\n",
      "  learn_throughput: 8407.156\n",
      "  learn_time_ms: 3.806\n",
      "  load_throughput: 142014.314\n",
      "  load_time_ms: 0.225\n",
      "  update_time_ms: 2.444\n",
      "timestamp: 1639929584\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 3000\n",
      "training_iteration: 3\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 4000\n",
      "custom_metrics: {}\n",
      "date: 2021-12-19_15-59-50\n",
      "done: false\n",
      "episode_len_mean: 24.91\n",
      "episode_media: {}\n",
      "episode_reward_max: 130.0\n",
      "episode_reward_mean: 24.91\n",
      "episode_reward_min: 8.0\n",
      "episodes_this_iter: 29\n",
      "episodes_total: 165\n",
      "experiment_id: e4b7e5fff46b45788ed74b177b87c05c\n",
      "hostname: run-61bf4c91992e0d71a81ef1b3-46bg7\n",
      "info:\n",
      "  last_target_update_ts: 3520\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 7.8745832443237305\n",
      "        mean_q: 5.396183967590332\n",
      "        mean_td_error: 0.5326855778694153\n",
      "        min_q: 2.039379835128784\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - 1.487060546875\n",
      "      - 0.37070512771606445\n",
      "      - -0.43299245834350586\n",
      "      - 0.22870254516601562\n",
      "      - -0.049424171447753906\n",
      "      - 0.13308334350585938\n",
      "      - 0.2632102966308594\n",
      "      - 0.053679466247558594\n",
      "      - 2.099306106567383\n",
      "      - 0.401792049407959\n",
      "      - -0.4167451858520508\n",
      "      - -0.049347877502441406\n",
      "      - 0.22119665145874023\n",
      "      - 0.3951892852783203\n",
      "      - -0.9050967693328857\n",
      "      - 3.666529655456543\n",
      "      - 0.4022684097290039\n",
      "      - 2.437007427215576\n",
      "      - 0.19928646087646484\n",
      "      - -0.27523231506347656\n",
      "      - 0.27967023849487305\n",
      "      - 0.22490644454956055\n",
      "      - 1.0393798351287842\n",
      "      - 0.4230227470397949\n",
      "      - 0.2651224136352539\n",
      "      - 0.3681216239929199\n",
      "      - 3.3559627532958984\n",
      "      - 0.2409663200378418\n",
      "      - 0.2146162986755371\n",
      "      - 0.1916794776916504\n",
      "      - -0.016839981079101562\n",
      "      - 0.22915172576904297\n",
      "  num_agent_steps_sampled: 4000\n",
      "  num_agent_steps_trained: 24032\n",
      "  num_steps_sampled: 4000\n",
      "  num_steps_trained: 24032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 6\n",
      "iterations_since_restore: 4\n",
      "node_ip: 10.0.47.10\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.5875\n",
      "  gpu_util_percent0: 0.0\n",
      "  ram_util_percent: 7.9\n",
      "  vram_util_percent0: 0.018997524752475247\n",
      "pid: 239\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07649366252763905\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07903856733760702\n",
      "  mean_inference_ms: 1.1700843808553607\n",
      "  mean_raw_obs_processing_ms: 0.17300402896252984\n",
      "time_since_restore: 20.444175481796265\n",
      "time_this_iter_s: 5.980470180511475\n",
      "time_total_s: 20.444175481796265\n",
      "timers:\n",
      "  learn_throughput: 8436.379\n",
      "  learn_time_ms: 3.793\n",
      "  load_throughput: 136719.698\n",
      "  load_time_ms: 0.234\n",
      "  update_time_ms: 2.441\n",
      "timestamp: 1639929590\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 4000\n",
      "training_iteration: 4\n",
      "trial_id: default\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 5000\n",
      "custom_metrics: {}\n",
      "date: 2021-12-19_15-59-56\n",
      "done: false\n",
      "episode_len_mean: 32.61\n",
      "episode_media: {}\n",
      "episode_reward_max: 139.0\n",
      "episode_reward_mean: 32.61\n",
      "episode_reward_min: 8.0\n",
      "episodes_this_iter: 11\n",
      "episodes_total: 176\n",
      "experiment_id: e4b7e5fff46b45788ed74b177b87c05c\n",
      "hostname: run-61bf4c91992e0d71a81ef1b3-46bg7\n",
      "info:\n",
      "  last_target_update_ts: 4528\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 9.091682434082031\n",
      "        mean_q: 6.57192325592041\n",
      "        mean_td_error: 0.20031186938285828\n",
      "        min_q: 0.7229157090187073\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - -0.07173919677734375\n",
      "      - -0.2770842909812927\n",
      "      - 4.919246673583984\n",
      "      - -1.2958145141601562\n",
      "      - 0.004993915557861328\n",
      "      - 0.06239604949951172\n",
      "      - 2.4069600105285645\n",
      "      - 0.10159873962402344\n",
      "      - -0.20542395114898682\n",
      "      - 2.918102264404297\n",
      "      - -0.3779282569885254\n",
      "      - 0.5631256103515625\n",
      "      - 0.05513572692871094\n",
      "      - -0.3672628402709961\n",
      "      - 0.07407188415527344\n",
      "      - 0.2792057991027832\n",
      "      - -0.21308231353759766\n",
      "      - -0.16952228546142578\n",
      "      - 0.03942584991455078\n",
      "      - 0.11183452606201172\n",
      "      - 0.1939171552658081\n",
      "      - 0.33249950408935547\n",
      "      - -0.14507198333740234\n",
      "      - 0.22051715850830078\n",
      "      - 0.1811838150024414\n",
      "      - -0.22621917724609375\n",
      "      - -0.15851974487304688\n",
      "      - 0.23381900787353516\n",
      "      - -0.6446733474731445\n",
      "      - -0.8377082347869873\n",
      "      - -0.4146556854248047\n",
      "      - -0.8833479881286621\n",
      "  num_agent_steps_sampled: 5000\n",
      "  num_agent_steps_trained: 32032\n",
      "  num_steps_sampled: 5000\n",
      "  num_steps_trained: 32032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 8\n",
      "iterations_since_restore: 5\n",
      "node_ip: 10.0.47.10\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.8375\n",
      "  gpu_util_percent0: 0.0\n",
      "  ram_util_percent: 7.9\n",
      "  vram_util_percent0: 0.018997524752475247\n",
      "pid: 239\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0764651382367548\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07904079315720226\n",
      "  mean_inference_ms: 1.1683596523205333\n",
      "  mean_raw_obs_processing_ms: 0.17238703824927126\n",
      "time_since_restore: 26.470868587493896\n",
      "time_this_iter_s: 6.026693105697632\n",
      "time_total_s: 26.470868587493896\n",
      "timers:\n",
      "  learn_throughput: 8515.489\n",
      "  learn_time_ms: 3.758\n",
      "  load_throughput: 138169.372\n",
      "  load_time_ms: 0.232\n",
      "  update_time_ms: 2.44\n",
      "timestamp: 1639929596\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 5000\n",
      "training_iteration: 5\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 6000\n",
      "custom_metrics: {}\n",
      "date: 2021-12-19_16-00-02\n",
      "done: false\n",
      "episode_len_mean: 40.28\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 40.28\n",
      "episode_reward_min: 8.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 184\n",
      "experiment_id: e4b7e5fff46b45788ed74b177b87c05c\n",
      "hostname: run-61bf4c91992e0d71a81ef1b3-46bg7\n",
      "info:\n",
      "  last_target_update_ts: 5536\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 10.980738639831543\n",
      "        mean_q: 8.955510139465332\n",
      "        mean_td_error: -0.08036400377750397\n",
      "        min_q: -0.3104342818260193\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - 0.16028881072998047\n",
      "      - 2.6054024696350098\n",
      "      - -0.8696837425231934\n",
      "      - 0.04449748992919922\n",
      "      - -1.310434341430664\n",
      "      - 0.4410238265991211\n",
      "      - -0.005255699157714844\n",
      "      - 0.3181953430175781\n",
      "      - -0.5747146606445312\n",
      "      - 0.1890239715576172\n",
      "      - -0.5459709167480469\n",
      "      - 0.23951339721679688\n",
      "      - -0.241912841796875\n",
      "      - -0.46640968322753906\n",
      "      - -0.5255575180053711\n",
      "      - -0.4312744140625\n",
      "      - -0.13446617126464844\n",
      "      - -0.4910469055175781\n",
      "      - 0.16363143920898438\n",
      "      - -0.1472759246826172\n",
      "      - -0.21587085723876953\n",
      "      - -0.3350362777709961\n",
      "      - 0.05957794189453125\n",
      "      - -0.7385497093200684\n",
      "      - 0.22152423858642578\n",
      "      - -0.21820068359375\n",
      "      - -0.42572498321533203\n",
      "      - -0.014781951904296875\n",
      "      - 0.40990161895751953\n",
      "      - 0.2509002685546875\n",
      "      - -0.2496356964111328\n",
      "      - 0.2666740417480469\n",
      "  num_agent_steps_sampled: 6000\n",
      "  num_agent_steps_trained: 40032\n",
      "  num_steps_sampled: 6000\n",
      "  num_steps_trained: 40032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 10\n",
      "iterations_since_restore: 6\n",
      "node_ip: 10.0.47.10\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 24.65555555555555\n",
      "  gpu_util_percent0: 0.0\n",
      "  ram_util_percent: 7.900000000000001\n",
      "  vram_util_percent0: 0.018997524752475247\n",
      "pid: 239\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07646438496435624\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07907105005600357\n",
      "  mean_inference_ms: 1.1674170109285844\n",
      "  mean_raw_obs_processing_ms: 0.17183056171562064\n",
      "time_since_restore: 32.77464461326599\n",
      "time_this_iter_s: 6.303776025772095\n",
      "time_total_s: 32.77464461326599\n",
      "timers:\n",
      "  learn_throughput: 7967.099\n",
      "  learn_time_ms: 4.017\n",
      "  load_throughput: 127692.634\n",
      "  load_time_ms: 0.251\n",
      "  update_time_ms: 2.906\n",
      "timestamp: 1639929602\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 6000\n",
      "training_iteration: 6\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 7000\n",
      "custom_metrics: {}\n",
      "date: 2021-12-19_16-00-09\n",
      "done: false\n",
      "episode_len_mean: 48.09\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 48.09\n",
      "episode_reward_min: 8.0\n",
      "episodes_this_iter: 14\n",
      "episodes_total: 198\n",
      "experiment_id: e4b7e5fff46b45788ed74b177b87c05c\n",
      "hostname: run-61bf4c91992e0d71a81ef1b3-46bg7\n",
      "info:\n",
      "  last_target_update_ts: 6544\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 12.045459747314453\n",
      "        mean_q: 10.406426429748535\n",
      "        mean_td_error: 0.6353520154953003\n",
      "        min_q: 4.594790458679199\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - -0.05082511901855469\n",
      "      - 0.17308902740478516\n",
      "      - 0.05584526062011719\n",
      "      - -0.25300025939941406\n",
      "      - 0.09177494049072266\n",
      "      - 0.1783924102783203\n",
      "      - -0.11349868774414062\n",
      "      - -1.0246047973632812\n",
      "      - 0.11536788940429688\n",
      "      - 4.482269287109375e-05\n",
      "      - -0.07539558410644531\n",
      "      - 0.007476806640625\n",
      "      - -0.07827281951904297\n",
      "      - -0.044391632080078125\n",
      "      - 3.7822909355163574\n",
      "      - 0.1350574493408203\n",
      "      - 0.28375720977783203\n",
      "      - -0.31267642974853516\n",
      "      - 7.503278732299805\n",
      "      - 0.22666072845458984\n",
      "      - 0.19960689544677734\n",
      "      - 0.1321420669555664\n",
      "      - 0.18231201171875\n",
      "      - 0.07486438751220703\n",
      "      - -0.296539306640625\n",
      "      - 3.594790458679199\n",
      "      - -0.03805828094482422\n",
      "      - 0.10984134674072266\n",
      "      - -0.32878875732421875\n",
      "      - 5.84437370300293\n",
      "      - 0.1865825653076172\n",
      "      - 0.06976795196533203\n",
      "  num_agent_steps_sampled: 7000\n",
      "  num_agent_steps_trained: 48032\n",
      "  num_steps_sampled: 7000\n",
      "  num_steps_trained: 48032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 12\n",
      "iterations_since_restore: 7\n",
      "node_ip: 10.0.47.10\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 28.255555555555556\n",
      "  gpu_util_percent0: 0.0\n",
      "  ram_util_percent: 7.900000000000001\n",
      "  vram_util_percent0: 0.018997524752475247\n",
      "pid: 239\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07651035962612127\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07917390925606277\n",
      "  mean_inference_ms: 1.16686671089008\n",
      "  mean_raw_obs_processing_ms: 0.17083425488096945\n",
      "time_since_restore: 39.11784553527832\n",
      "time_this_iter_s: 6.343200922012329\n",
      "time_total_s: 39.11784553527832\n",
      "timers:\n",
      "  learn_throughput: 7109.027\n",
      "  learn_time_ms: 4.501\n",
      "  load_throughput: 116085.217\n",
      "  load_time_ms: 0.276\n",
      "  update_time_ms: 3.057\n",
      "timestamp: 1639929609\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 7000\n",
      "training_iteration: 7\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 8000\n",
      "custom_metrics: {}\n",
      "date: 2021-12-19_16-00-15\n",
      "done: false\n",
      "episode_len_mean: 56.21\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 56.21\n",
      "episode_reward_min: 8.0\n",
      "episodes_this_iter: 9\n",
      "episodes_total: 207\n",
      "experiment_id: e4b7e5fff46b45788ed74b177b87c05c\n",
      "hostname: run-61bf4c91992e0d71a81ef1b3-46bg7\n",
      "info:\n",
      "  last_target_update_ts: 7552\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 13.452073097229004\n",
      "        mean_q: 11.152207374572754\n",
      "        mean_td_error: 0.0327465645968914\n",
      "        min_q: -0.6356433629989624\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - -0.2584648132324219\n",
      "      - -0.22556018829345703\n",
      "      - -1.0733003616333008\n",
      "      - -0.06968212127685547\n",
      "      - 0.23694992065429688\n",
      "      - 0.112457275390625\n",
      "      - -0.006670951843261719\n",
      "      - -0.3028993606567383\n",
      "      - 0.31780338287353516\n",
      "      - -0.05245399475097656\n",
      "      - -1.4274492263793945\n",
      "      - 0.1308889389038086\n",
      "      - 2.1570351123809814\n",
      "      - 0.37061595916748047\n",
      "      - 0.2834806442260742\n",
      "      - -1.6356433629989624\n",
      "      - -0.18532562255859375\n",
      "      - 0.28636646270751953\n",
      "      - 0.17223072052001953\n",
      "      - -0.040309906005859375\n",
      "      - -0.18987083435058594\n",
      "      - 0.5138788223266602\n",
      "      - 0.1361675262451172\n",
      "      - 0.01129150390625\n",
      "      - 0.0042476654052734375\n",
      "      - -0.14899253845214844\n",
      "      - -0.3207712173461914\n",
      "      - -0.060439109802246094\n",
      "      - 0.040241241455078125\n",
      "      - 0.0219268798828125\n",
      "      - -0.4285764694213867\n",
      "      - 2.678718090057373\n",
      "  num_agent_steps_sampled: 8000\n",
      "  num_agent_steps_trained: 56032\n",
      "  num_steps_sampled: 8000\n",
      "  num_steps_trained: 56032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 14\n",
      "iterations_since_restore: 8\n",
      "node_ip: 10.0.47.10\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.1\n",
      "  gpu_util_percent0: 0.0\n",
      "  ram_util_percent: 7.9\n",
      "  vram_util_percent0: 0.018997524752475247\n",
      "pid: 239\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07653868774233098\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07921990586058396\n",
      "  mean_inference_ms: 1.1665581682499906\n",
      "  mean_raw_obs_processing_ms: 0.17007175645979825\n",
      "time_since_restore: 45.185750246047974\n",
      "time_this_iter_s: 6.067904710769653\n",
      "time_total_s: 45.185750246047974\n",
      "timers:\n",
      "  learn_throughput: 7359.195\n",
      "  learn_time_ms: 4.348\n",
      "  load_throughput: 118682.225\n",
      "  load_time_ms: 0.27\n",
      "  update_time_ms: 2.822\n",
      "timestamp: 1639929615\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 8000\n",
      "training_iteration: 8\n",
      "trial_id: default\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 9000\n",
      "custom_metrics: {}\n",
      "date: 2021-12-19_16-00-21\n",
      "done: false\n",
      "episode_len_mean: 63.62\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 63.62\n",
      "episode_reward_min: 8.0\n",
      "episodes_this_iter: 8\n",
      "episodes_total: 215\n",
      "experiment_id: e4b7e5fff46b45788ed74b177b87c05c\n",
      "hostname: run-61bf4c91992e0d71a81ef1b3-46bg7\n",
      "info:\n",
      "  last_target_update_ts: 8560\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 15.408904075622559\n",
      "        mean_q: 12.299129486083984\n",
      "        mean_td_error: 0.4111831784248352\n",
      "        min_q: -0.7559371590614319\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - 1.2872157096862793\n",
      "      - -0.0954294204711914\n",
      "      - -1.755937099456787\n",
      "      - 0.33522891998291016\n",
      "      - 4.729964256286621\n",
      "      - 0.3840465545654297\n",
      "      - 0.29047584533691406\n",
      "      - 0.5781755447387695\n",
      "      - 0.18021392822265625\n",
      "      - -0.3184385299682617\n",
      "      - 0.284210205078125\n",
      "      - 4.8803391456604\n",
      "      - -0.0751047134399414\n",
      "      - 0.20831584930419922\n",
      "      - 0.3594331741333008\n",
      "      - -0.9473609924316406\n",
      "      - 0.3195638656616211\n",
      "      - -0.940185546875\n",
      "      - 0.22014713287353516\n",
      "      - 0.21658802032470703\n",
      "      - 0.14519023895263672\n",
      "      - 0.3013753890991211\n",
      "      - 0.04264354705810547\n",
      "      - 0.3112163543701172\n",
      "      - 0.3280906677246094\n",
      "      - 0.4516181945800781\n",
      "      - 0.27834606170654297\n",
      "      - 0.3067197799682617\n",
      "      - 0.2587442398071289\n",
      "      - 0.26986122131347656\n",
      "      - 0.3456411361694336\n",
      "      - -0.023047447204589844\n",
      "  num_agent_steps_sampled: 9000\n",
      "  num_agent_steps_trained: 64032\n",
      "  num_steps_sampled: 9000\n",
      "  num_steps_trained: 64032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 16\n",
      "iterations_since_restore: 9\n",
      "node_ip: 10.0.47.10\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 25.450000000000003\n",
      "  gpu_util_percent0: 0.0\n",
      "  ram_util_percent: 7.9\n",
      "  vram_util_percent0: 0.018997524752475247\n",
      "pid: 239\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.07657376712556029\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07927352290091004\n",
      "  mean_inference_ms: 1.1662668685933482\n",
      "  mean_raw_obs_processing_ms: 0.16934848955949408\n",
      "time_since_restore: 51.32378053665161\n",
      "time_this_iter_s: 6.138030290603638\n",
      "time_total_s: 51.32378053665161\n",
      "timers:\n",
      "  learn_throughput: 8285.914\n",
      "  learn_time_ms: 3.862\n",
      "  load_throughput: 138941.747\n",
      "  load_time_ms: 0.23\n",
      "  update_time_ms: 2.579\n",
      "timestamp: 1639929621\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 9000\n",
      "training_iteration: 9\n",
      "trial_id: default\n",
      "\n",
      "agent_timesteps_total: 10000\n",
      "custom_metrics: {}\n",
      "date: 2021-12-19_16-00-27\n",
      "done: false\n",
      "episode_len_mean: 72.93\n",
      "episode_media: {}\n",
      "episode_reward_max: 200.0\n",
      "episode_reward_mean: 72.93\n",
      "episode_reward_min: 8.0\n",
      "episodes_this_iter: 6\n",
      "episodes_total: 221\n",
      "experiment_id: e4b7e5fff46b45788ed74b177b87c05c\n",
      "hostname: run-61bf4c91992e0d71a81ef1b3-46bg7\n",
      "info:\n",
      "  last_target_update_ts: 9568\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      learner_stats:\n",
      "        cur_lr: 0.0005000000237487257\n",
      "        max_q: 17.46268081665039\n",
      "        mean_q: 14.897810935974121\n",
      "        mean_td_error: 0.08951301872730255\n",
      "        min_q: 0.18849235773086548\n",
      "        model: {}\n",
      "      td_error:\n",
      "      - 0.2897529602050781\n",
      "      - 0.32984161376953125\n",
      "      - 7.916614532470703\n",
      "      - -1.757425308227539\n",
      "      - -0.38641834259033203\n",
      "      - -0.036652565002441406\n",
      "      - -0.06272697448730469\n",
      "      - 0.4716949462890625\n",
      "      - 0.17266464233398438\n",
      "      - 1.1584854125976562\n",
      "      - -2.0560684204101562\n",
      "      - -0.8115076422691345\n",
      "      - -0.2399749755859375\n",
      "      - -0.020215988159179688\n",
      "      - -0.01088714599609375\n",
      "      - -1.1644096374511719\n",
      "      - 0.15056228637695312\n",
      "      - 0.500457763671875\n",
      "      - -0.29163074493408203\n",
      "      - 0.3165130615234375\n",
      "      - -0.7744932174682617\n",
      "      - -0.8242616653442383\n",
      "      - 0.3991203308105469\n",
      "      - 0.3978443145751953\n",
      "      - -0.19919967651367188\n",
      "      - 0.25901222229003906\n",
      "      - 0.0849609375\n",
      "      - 0.03357696533203125\n",
      "      - -0.3572578430175781\n",
      "      - -0.08539581298828125\n",
      "      - -0.4393758773803711\n",
      "      - -0.09878349304199219\n",
      "  num_agent_steps_sampled: 10000\n",
      "  num_agent_steps_trained: 72032\n",
      "  num_steps_sampled: 10000\n",
      "  num_steps_trained: 72032\n",
      "  num_steps_trained_this_iter: 0\n",
      "  num_target_updates: 18\n",
      "iterations_since_restore: 10\n",
      "node_ip: 10.0.47.10\n",
      "num_healthy_workers: 1\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 27.4625\n",
      "  gpu_util_percent0: 0.0\n",
      "  ram_util_percent: 7.9\n",
      "  vram_util_percent0: 0.018997524752475247\n",
      "pid: 239\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0765971206514279\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.07931582617471734\n",
      "  mean_inference_ms: 1.1660297821955097\n",
      "  mean_raw_obs_processing_ms: 0.16875760926238206\n",
      "time_since_restore: 57.483179569244385\n",
      "time_this_iter_s: 6.159399032592773\n",
      "time_total_s: 57.483179569244385\n",
      "timers:\n",
      "  learn_throughput: 7575.39\n",
      "  learn_time_ms: 4.224\n",
      "  load_throughput: 133749.604\n",
      "  load_time_ms: 0.239\n",
      "  update_time_ms: 2.74\n",
      "timestamp: 1639929627\n",
      "timesteps_since_restore: 0\n",
      "timesteps_this_iter: 0\n",
      "timesteps_total: 10000\n",
      "training_iteration: 10\n",
      "trial_id: default\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import ray.rllib.agents.dqn as dqn\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "config = dqn.DEFAULT_CONFIG.copy()\n",
    "config[\"num_gpus\"] = 0\n",
    "config[\"num_workers\"] = 1\n",
    "trainer = dqn.DQNTrainer(config=config, env=\"CartPole-v0\")\n",
    "\n",
    "# Can optionally call trainer.restore(path) to load a checkpoint.\n",
    "\n",
    "for i in range(10):\n",
    "   # Perform one iteration of training the policy with PPO\n",
    "   result = trainer.train()\n",
    "   print(pretty_print(result))\n",
    "\n",
    "   if i % 100 == 0:\n",
    "       checkpoint = trainer.save()\n",
    "       print(\"checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the Results\n",
    "\n",
    "Let's take a look at the results of our training.  Which "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQN_CartPole-v0_2021-12-19_15-29-396lylsdgf\r\n"
     ]
    }
   ],
   "source": [
    "#print path to logs\n",
    "\n",
    "!ls ~/ray_results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose the log file>DQN_CartPole-v0_2021-12-19_15-29-396lylsdgf\n"
     ]
    }
   ],
   "source": [
    "logs_path = input('Choose the log file>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>timesteps_this_iter</th>\n",
       "      <th>agent_timesteps_total</th>\n",
       "      <th>done</th>\n",
       "      <th>...</th>\n",
       "      <th>perf/cpu_util_percent</th>\n",
       "      <th>perf/ram_util_percent</th>\n",
       "      <th>perf/gpu_util_percent0</th>\n",
       "      <th>perf/vram_util_percent0</th>\n",
       "      <th>info/learner/default_policy/td_error</th>\n",
       "      <th>info/learner/default_policy/learner_stats/cur_lr</th>\n",
       "      <th>info/learner/default_policy/learner_stats/mean_q</th>\n",
       "      <th>info/learner/default_policy/learner_stats/min_q</th>\n",
       "      <th>info/learner/default_policy/learner_stats/max_q</th>\n",
       "      <th>info/learner/default_policy/learner_stats/mean_td_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.809524</td>\n",
       "      <td>23.809524</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>13.9500</td>\n",
       "      <td>7.3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>[-1.3272281  -1.6428953  -1.1148595  -1.059449...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-0.232039</td>\n",
       "      <td>-0.884704</td>\n",
       "      <td>0.021835</td>\n",
       "      <td>-1.241704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.885057</td>\n",
       "      <td>22.885057</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0750</td>\n",
       "      <td>7.4625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>[ 0.44298553  0.7839279  -0.47713804  0.265240...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>2.229970</td>\n",
       "      <td>1.442986</td>\n",
       "      <td>3.066627</td>\n",
       "      <td>-0.002296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24.040000</td>\n",
       "      <td>24.040000</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "      <td>3000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>24.8000</td>\n",
       "      <td>7.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>[-0.2948475  -0.01530695  1.0656462   0.194376...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3.782262</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>5.440300</td>\n",
       "      <td>0.032147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>27.870000</td>\n",
       "      <td>27.870000</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>0</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>25.4250</td>\n",
       "      <td>7.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>[ 1.9637122   0.02317286 -0.49960113 -0.232507...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>5.371221</td>\n",
       "      <td>2.229071</td>\n",
       "      <td>6.948530</td>\n",
       "      <td>0.360913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>34.280000</td>\n",
       "      <td>34.280000</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>24.3375</td>\n",
       "      <td>7.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018998</td>\n",
       "      <td>[ 0.02216434  6.6001015   0.1020174  -0.870739...</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>7.366294</td>\n",
       "      <td>2.446815</td>\n",
       "      <td>8.898622</td>\n",
       "      <td>0.228439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0                57.0                10.0            23.809524   \n",
       "1                57.0                 9.0            22.885057   \n",
       "2                66.0                 9.0            24.040000   \n",
       "3                97.0                 9.0            27.870000   \n",
       "4               160.0                 9.0            34.280000   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_healthy_workers  timesteps_total  \\\n",
       "0         23.809524                  42                    1             1000   \n",
       "1         22.885057                  45                    1             2000   \n",
       "2         24.040000                  38                    1             3000   \n",
       "3         27.870000                  25                    1             4000   \n",
       "4         34.280000                  12                    1             5000   \n",
       "\n",
       "   timesteps_this_iter  agent_timesteps_total   done  ...  \\\n",
       "0                    0                   1000  False  ...   \n",
       "1                    0                   2000  False  ...   \n",
       "2                    0                   3000  False  ...   \n",
       "3                    0                   4000  False  ...   \n",
       "4                    0                   5000  False  ...   \n",
       "\n",
       "   perf/cpu_util_percent  perf/ram_util_percent perf/gpu_util_percent0  \\\n",
       "0                13.9500                 7.3000                    0.0   \n",
       "1                24.0750                 7.4625                    0.0   \n",
       "2                24.8000                 7.5000                    0.0   \n",
       "3                25.4250                 7.5000                    0.0   \n",
       "4                24.3375                 7.5000                    0.0   \n",
       "\n",
       "  perf/vram_util_percent0               info/learner/default_policy/td_error  \\\n",
       "0                0.018998  [-1.3272281  -1.6428953  -1.1148595  -1.059449...   \n",
       "1                0.018998  [ 0.44298553  0.7839279  -0.47713804  0.265240...   \n",
       "2                0.018998  [-0.2948475  -0.01530695  1.0656462   0.194376...   \n",
       "3                0.018998  [ 1.9637122   0.02317286 -0.49960113 -0.232507...   \n",
       "4                0.018998  [ 0.02216434  6.6001015   0.1020174  -0.870739...   \n",
       "\n",
       "   info/learner/default_policy/learner_stats/cur_lr  \\\n",
       "0                                            0.0005   \n",
       "1                                            0.0005   \n",
       "2                                            0.0005   \n",
       "3                                            0.0005   \n",
       "4                                            0.0005   \n",
       "\n",
       "   info/learner/default_policy/learner_stats/mean_q  \\\n",
       "0                                         -0.232039   \n",
       "1                                          2.229970   \n",
       "2                                          3.782262   \n",
       "3                                          5.371221   \n",
       "4                                          7.366294   \n",
       "\n",
       "   info/learner/default_policy/learner_stats/min_q  \\\n",
       "0                                        -0.884704   \n",
       "1                                         1.442986   \n",
       "2                                         0.931887   \n",
       "3                                         2.229071   \n",
       "4                                         2.446815   \n",
       "\n",
       "   info/learner/default_policy/learner_stats/max_q  \\\n",
       "0                                         0.021835   \n",
       "1                                         3.066627   \n",
       "2                                         5.440300   \n",
       "3                                         6.948530   \n",
       "4                                         8.898622   \n",
       "\n",
       "  info/learner/default_policy/learner_stats/mean_td_error  \n",
       "0                                          -1.241704       \n",
       "1                                          -0.002296       \n",
       "2                                           0.032147       \n",
       "3                                           0.360913       \n",
       "4                                           0.228439       \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# choose the path to your output logs\n",
    "logs_path = logs_path\n",
    "data_path = '~/ray_results/{}/progress.csv'.format(logs_path)\n",
    "graph_file = 'progress.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create dataframe with pertinent information and graph the episode reward mean against the episode  per iteration\n",
    "\n",
    "episodes_this_iter = df['episodes_this_iter']\n",
    "episodes_total = df['episodes_total']\n",
    "episodes_reward_mean = df['episode_reward_mean']\n",
    "episodes_reward_max = df['episode_reward_max']\n",
    "episodes_reward_min = df['episode_reward_min']\n",
    "\n",
    "df_episodes = pd.DataFrame(episodes_total)\n",
    "df_episodes['episodes_reward_mean'] = df['episode_reward_mean']\n",
    "df_episodes[\"episodes_reward_min\"] = df['episode_reward_min']\n",
    "df_episodes[\"episodes_reward_max\"] = df['episode_reward_max']\n",
    "\n",
    "df_episodes.plot.line()\n",
    "\n",
    "## here we see the total number of episodes has increased overall but in each iteration, fewer episodes are required \n",
    "## to achieve a higher reward.  We see the algorithm learning more quickly towards the end when it reaches its maximum\n",
    "## iterations and thus its best rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_disable_preprocessor_api': False,\n",
      " '_time_major': False,\n",
      " '_use_default_native_models': False,\n",
      " 'attention_dim': 64,\n",
      " 'attention_head_dim': 32,\n",
      " 'attention_init_gru_gate_bias': 2.0,\n",
      " 'attention_memory_inference': 50,\n",
      " 'attention_memory_training': 50,\n",
      " 'attention_num_heads': 1,\n",
      " 'attention_num_transformer_units': 1,\n",
      " 'attention_position_wise_mlp_dim': 32,\n",
      " 'attention_use_n_prev_actions': 0,\n",
      " 'attention_use_n_prev_rewards': 0,\n",
      " 'conv_activation': 'relu',\n",
      " 'conv_filters': None,\n",
      " 'custom_action_dist': None,\n",
      " 'custom_model': None,\n",
      " 'custom_model_config': {},\n",
      " 'custom_preprocessor': None,\n",
      " 'dim': 84,\n",
      " 'fcnet_activation': 'tanh',\n",
      " 'fcnet_hiddens': [256, 256],\n",
      " 'framestack': True,\n",
      " 'free_log_std': False,\n",
      " 'grayscale': False,\n",
      " 'lstm_cell_size': 256,\n",
      " 'lstm_use_prev_action': False,\n",
      " 'lstm_use_prev_action_reward': -1,\n",
      " 'lstm_use_prev_reward': False,\n",
      " 'max_seq_len': 20,\n",
      " 'no_final_linear': True,\n",
      " 'post_fcnet_activation': 'relu',\n",
      " 'post_fcnet_hiddens': [],\n",
      " 'use_attention': False,\n",
      " 'use_lstm': False,\n",
      " 'vf_share_layers': True,\n",
      " 'zero_mean': True}\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "\n",
    "policy = trainer.get_policy()\n",
    "model = policy.model\n",
    "pp.pprint(model.model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom Environment and Optimized Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ray.is_initialized() == False:\n",
    "   service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "   service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "   _temp_dir='/domino/datasets/local/{}/'.format(os.environ['DOMINO_PROJECT_NAME']) #set to a dataset\n",
    "   ray.util.connect(f\"{service_host}:{service_port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a custom environment; adapted from Ray documentation\n",
    "\n",
    "\"\"\"Example of a custom gym environment and model. Run this for a demo.\n",
    "\n",
    "This example shows:\n",
    "  - using a custom environment\n",
    "  - using a custom model\n",
    "  - using Tune for grid search\n",
    "\n",
    "You can visualize experiment results in ~/ray_results using TensorBoard.\n",
    "\"\"\"\n",
    "#ray.shutdown()\n",
    "#ray.init()\n",
    "\n",
    "import argparse\n",
    "import gym\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import grid_search\n",
    "from ray.rllib.env.env_context import EnvContext\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.tf.tf_modelv2 import TFModelV2\n",
    "from ray.rllib.models.tf.fcnet import FullyConnectedNetwork\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork as TorchFC\n",
    "from ray.rllib.utils.framework import try_import_tf, try_import_torch\n",
    "from ray.rllib.utils.test_utils import check_learning_achieved\n",
    "\n",
    "torch, nn = try_import_torch()\n",
    "run = 'DQN'\n",
    "framework = 'torch'\n",
    "as_test=\"store_true\"\n",
    "stop_iters = 50\n",
    "stop_timesteps = 100000\n",
    "stop_reward = 0.1\n",
    "\n",
    "class SimpleCorridor(gym.Env):\n",
    "    \"\"\"Example of a custom env in which you have to walk down a corridor.\n",
    "\n",
    "    You can configure the length of the corridor via the env config.\"\"\"\n",
    "\n",
    "    def __init__(self, config: EnvContext):\n",
    "        self.end_pos = config[\"corridor_length\"]\n",
    "        self.cur_pos = 0\n",
    "        self.action_space = Discrete(2)\n",
    "        self.observation_space = Box(\n",
    "            0.0, self.end_pos, shape=(1, ), dtype=np.float32)\n",
    "        # Set the seed. This is only used for the final (reach goal) reward.\n",
    "        self.seed(config.worker_index * config.num_workers)\n",
    "\n",
    "    def reset(self):\n",
    "        self.cur_pos = 0\n",
    "        return [self.cur_pos]\n",
    "\n",
    "    def step(self, action):\n",
    "        assert action in [0, 1], action\n",
    "        if action == 0 and self.cur_pos > 0:\n",
    "            self.cur_pos -= 1\n",
    "        elif action == 1:\n",
    "            self.cur_pos += 1\n",
    "        done = self.cur_pos >= self.end_pos\n",
    "        # Produce a random reward when we reach the goal.\n",
    "        return [self.cur_pos], \\\n",
    "            random.random() * 2 if done else -0.1, done, {}\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        random.seed(seed)\n",
    "\n",
    "class TorchCustomModel(TorchModelV2, nn.Module):\n",
    "    \"\"\"Example of a PyTorch custom model that just delegates to a fc-net.\"\"\"\n",
    "\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config,\n",
    "                 name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs,\n",
    "                              model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        self.torch_sub_model = TorchFC(obs_space, action_space, num_outputs,\n",
    "                                       model_config, name)\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        input_dict[\"obs\"] = input_dict[\"obs\"].float()\n",
    "        fc_out, _ = self.torch_sub_model(input_dict, state, seq_lens)\n",
    "        return fc_out, []\n",
    "\n",
    "    def value_function(self):\n",
    "        return torch.reshape(self.torch_sub_model.value_function(), [-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Current time: 2021-12-19 15:36:10 (running for 00:00:00.17)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Memory usage on this node: 3.6/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Resources requested: 0/35 CPUs, 0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result logdir: /domino/datasets/local/Ray_Quick_Start/DQN\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Number of trials: 3/3 (3 PENDING)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | Trial name                     | status   | loc   |     lr |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m |--------------------------------+----------+-------+--------|\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00000 | PENDING  |       | 0.01   |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00001 | PENDING  |       | 0.0001 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00002 | PENDING  |       | 1e-06  |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQN pid=149, ip=10.0.60.5)\u001b[0m 2021-12-19 15:36:14,937\tWARNING deprecation.py:45 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=149, ip=10.0.60.5)\u001b[0m 2021-12-19 15:36:14,937\tINFO dqn.py:141 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=149, ip=10.0.60.5)\u001b[0m 2021-12-19 15:36:14,937\tINFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=770, ip=10.0.41.148)\u001b[0m 2021-12-19 15:36:15,156\tWARNING deprecation.py:45 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=770, ip=10.0.41.148)\u001b[0m 2021-12-19 15:36:15,157\tINFO dqn.py:141 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=770, ip=10.0.41.148)\u001b[0m 2021-12-19 15:36:15,157\tINFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=77, ip=10.0.37.253)\u001b[0m 2021-12-19 15:36:15,578\tWARNING deprecation.py:45 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=77, ip=10.0.37.253)\u001b[0m 2021-12-19 15:36:15,578\tINFO dqn.py:141 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQN pid=77, ip=10.0.37.253)\u001b[0m 2021-12-19 15:36:15,578\tINFO trainer.py:743 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQN pid=149, ip=10.0.60.5)\u001b[0m 2021-12-19 15:36:18,932\tWARNING deprecation.py:45 -- DeprecationWarning: `convert_to_non_torch_type` has been deprecated. Use `ray/rllib/utils/numpy.py::convert_to_numpy` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=770, ip=10.0.41.148)\u001b[0m 2021-12-19 15:36:18,907\tWARNING deprecation.py:45 -- DeprecationWarning: `convert_to_non_torch_type` has been deprecated. Use `ray/rllib/utils/numpy.py::convert_to_numpy` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQN pid=77, ip=10.0.37.253)\u001b[0m 2021-12-19 15:36:19,558\tWARNING deprecation.py:45 -- DeprecationWarning: `convert_to_non_torch_type` has been deprecated. Use `ray/rllib/utils/numpy.py::convert_to_numpy` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Current time: 2021-12-19 15:36:19 (running for 00:00:09.37)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Memory usage on this node: 3.7/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Resources requested: 3.0/35 CPUs, 3.0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result logdir: /domino/datasets/local/Ray_Quick_Start/DQN\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Number of trials: 3/3 (3 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-----------------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | Trial name                     | status   | loc             |     lr |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m |--------------------------------+----------+-----------------+--------|\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00000 | RUNNING  | 10.0.60.5:149   | 0.01   |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00001 | RUNNING  | 10.0.41.148:770 | 0.0001 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00002 | RUNNING  | 10.0.37.253:77  | 1e-06  |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-----------------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Current time: 2021-12-19 15:36:21 (running for 00:00:11.42)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Memory usage on this node: 3.7/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Resources requested: 3.0/35 CPUs, 3.0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result logdir: /domino/datasets/local/Ray_Quick_Start/DQN\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Number of trials: 3/3 (3 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-----------------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | Trial name                     | status   | loc             |     lr |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m |--------------------------------+----------+-----------------+--------|\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00000 | RUNNING  | 10.0.60.5:149   | 0.01   |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00001 | RUNNING  | 10.0.41.148:770 | 0.0001 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00002 | RUNNING  | 10.0.37.253:77  | 1e-06  |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-----------------+--------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00000:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-22\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 27.305555555555557\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.216079714319183\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -1.656602201818141\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -9.156749169807405\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 36\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 36\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: 92fec9273b2e46d1ad58bc09e3dc93ad\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 0.01\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.6381741166114807\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: 0.018405286595225334\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: -0.6768853068351746\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: -0.20470848679542542\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.08793079853057861\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.3937031328678131\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10402554273605347\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.3937031328678131\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.1728483438491821\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.5768852829933167\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10402554273605347\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.0598766803741455\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.08793079853057861\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.1902594566345215\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.08793079853057861\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.0598766803741455\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.5768852829933167\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.3937031328678131\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.014835894107818604\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.5768852829933167\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.3937031328678131\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.014835894107818604\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10402554273605347\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.014835894107818604\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.3937031328678131\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.60.5\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 14.86\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.05\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08607673267326732\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 149\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06387998293210695\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.04963226966210059\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.763804141339008\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.18095112704373262\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 3.321467876434326\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 3.321467876434326\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 3.321467876434326\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 2281.024\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 14.029\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 33884.809\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.944\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928182\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00001:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-22\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 38.5\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 0.6491210429593881\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -2.811086131094788\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -7.461486486020717\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 24\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 24\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: f3ef094fd1234ee5bedb38f5fd2ace46\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-3\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 0.0001\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.9675370454788208\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: 0.4519076347351074\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: 0.0043592676520347595\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.20088589191436768\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.9061753153800964\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.11231780052185059\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1293383240699768\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2629380226135254\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.9061753153800964\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.24686592817306519\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.3798578977584839\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.6981135010719299\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.24686592817306519\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2629380226135254\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.6981135010719299\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.6981135010719299\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2090129852294922\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.9061753153800964\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.6981135010719299\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.6981135010719299\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2090129852294922\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.6981135010719299\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.24686592817306519\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.9061753153800964\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1293383240699768\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.9061753153800964\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.24686592817306519\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.6981135010719299\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.6981135010719299\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.41.148\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 15.280000000000001\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.044000000000000004\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08607673267326732\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 770\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06685223612751995\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.055362651874492706\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.9775307966874434\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.18987003025355995\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 3.5687034130096436\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 3.5687034130096436\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 3.5687034130096436\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 2197.265\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 14.564\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 34160.786\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.937\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928182\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00001\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00002:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-22\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 23.186046511627907\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.3483537645997843\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -1.224193862227773\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -6.753835120359632\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 43\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 43\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: 7aca033a6d2a4b5eb373ff4c3af579e8\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 1.0e-06\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: -0.5998052358627319\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: -1.0188840627670288\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: -0.15165257453918457\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.21627259254455566\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.28427183628082275\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.11171829700469971\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.79753577709198\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.6114647388458252\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -2.5055806636810303\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.267869234085083\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.6114647388458252\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.39314818382263184\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.39314818382263184\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.11171829700469971\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.79753577709198\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.6114647388458252\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.79753577709198\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.39314818382263184\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10000000149011612\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.28427183628082275\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.39314818382263184\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.6114647388458252\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.79753577709198\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.21627259254455566\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09585016965866089\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.79753577709198\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.21627259254455566\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09585016965866089\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.21627259254455566\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09585016965866089\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.11171829700469971\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.28427183628082275\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 32\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.37.253\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 14.719999999999999\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.05\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08607673267326732\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 77\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06526833647614591\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.05211410941658438\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.788843808474241\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.19018561928184122\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 3.360745906829834\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 3.360745906829834\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 3.360745906829834\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 2216.057\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 14.44\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 34843.647\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.918\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928182\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 1000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00002\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Current time: 2021-12-19 15:36:27 (running for 00:00:16.77)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Memory usage on this node: 3.7/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Resources requested: 3.0/35 CPUs, 3.0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result logdir: /domino/datasets/local/Ray_Quick_Start/DQN\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Number of trials: 3/3 (3 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | Trial name                     | status   | loc             |     lr |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m |--------------------------------+----------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00000 | RUNNING  | 10.0.60.5:149   | 0.01   |      1 |          3.32147 | 1000 | -1.6566  |             1.21608  |             -9.15675 |            27.3056 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00001 | RUNNING  | 10.0.41.148:770 | 0.0001 |      1 |          3.5687  | 1000 | -2.81109 |             0.649121 |             -7.46149 |            38.5    |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00002 | RUNNING  | 10.0.37.253:77  | 1e-06  |      1 |          3.36075 | 1000 | -1.22419 |             1.34835  |             -6.75384 |            23.186  |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00000:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 2000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-29\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 26.4\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.216079714319183\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -1.609753824237557\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -9.156749169807405\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 39\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 75\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: 92fec9273b2e46d1ad58bc09e3dc93ad\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 1504\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 0.01\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.8424499034881592\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: 0.8301213979721069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: 0.8175748586654663\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: -0.008015824481844902\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2266169786453247\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10855072736740112\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.21493077278137207\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.12314677238464355\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.5284445881843567\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2266169786453247\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2266169786453247\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.09065902233123779\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2266169786453247\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.12314677238464355\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10855072736740112\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1603425145149231\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19891178607940674\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2266169786453247\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2266169786453247\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.08490300178527832\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10855072736740112\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2266169786453247\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1736844778060913\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.21493077278137207\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1736844778060913\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.08490300178527832\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.21493077278137207\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.09065902233123779\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19891178607940674\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1736844778060913\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.09065902233123779\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2266169786453247\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.12314677238464355\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10855072736740112\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10855072736740112\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.12314677238464355\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 2000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 8032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 2000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 8032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.60.5\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 15.277777777777779\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.05555555555555555\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08691556655665567\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 149\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06371411755434012\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.04952905858926771\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.722377897120629\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.1811032932991075\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 10.408016681671143\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.086548805236816\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 10.408016681671143\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 3058.299\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 10.463\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 7072.913\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 4.524\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928189\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 2000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00001:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 2000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-30\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 28.154929577464788\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.1581613391152907\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -1.738554768908724\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -7.461486486020717\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 47\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 71\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: f3ef094fd1234ee5bedb38f5fd2ace46\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-3\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 1504\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 0.0001\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.6045228242874146\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: 0.39665380120277405\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: 0.1808174103498459\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: -0.06160769239068031\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0766758918762207\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.0008890032768249512\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.05721798539161682\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.11689844727516174\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.08207805454730988\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.03895255923271179\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.08207805454730988\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.05721798539161682\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0006537437438964844\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.08207805454730988\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0006537437438964844\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.003197312355041504\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.08207805454730988\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.9064466953277588\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.11689844727516174\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.0187345743179321\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1354866325855255\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.003197312355041504\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0766758918762207\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1354866325855255\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.03895255923271179\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.08207805454730988\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.3909462094306946\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.11689844727516174\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.003197312355041504\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1354866325855255\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.08207805454730988\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.003197312355041504\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.03895255923271179\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.08207805454730988\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.11689844727516174\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1354866325855255\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 2000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 8032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 2000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 8032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.41.148\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 15.5\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.053000000000000005\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08690594059405939\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 770\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06633737969539369\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.054894000412840205\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.926874574830428\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.19090243822061867\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 11.071101903915405\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.502398490905762\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 11.071101903915405\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 3047.819\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 10.499\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 35753.257\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.895\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928190\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 2000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00001\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00002:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 2000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-30\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 23.927710843373493\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.4791933238366712\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -1.2698708807982904\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -7.6155857812863\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 40\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 83\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: 7aca033a6d2a4b5eb373ff4c3af579e8\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 1504\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 1.0e-06\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.0004202465061098337\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: -0.2630220353603363\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: -0.5653420686721802\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: 0.054686740040779114\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1000204011797905\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.1845622062683105\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.5424433350563049\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1000204011797905\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1000204011797905\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.5424433350563049\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1000204011797905\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -2.350287675857544\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.9739298820495605\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.5424433350563049\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1000204011797905\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.3956524133682251\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.17047876119613647\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.17047876119613647\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.10571187734603882\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.5424433350563049\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.2562708556652069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1000204011797905\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.5424433350563049\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.17047876119613647\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.2562708556652069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.17047876119613647\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.5424433350563049\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.008772313594818115\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.2562708556652069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1000204011797905\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09149700403213501\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.5424433350563049\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.17047876119613647\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.008772313594818115\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1000204011797905\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.2562708556652069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 2000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 8032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 2000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 8032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.37.253\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 15.255555555555556\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.060000000000000005\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08691556655665567\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 77\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06508641095389707\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.05200871689548156\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.762104273070839\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.1903973725167624\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 10.54377269744873\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.1830267906188965\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 10.54377269744873\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 2243.457\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 14.264\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 37849.392\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.845\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928190\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 2000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00002\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Current time: 2021-12-19 15:36:32 (running for 00:00:22.02)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Memory usage on this node: 3.7/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Resources requested: 3.0/35 CPUs, 3.0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result logdir: /domino/datasets/local/Ray_Quick_Start/DQN\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Number of trials: 3/3 (3 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | Trial name                     | status   | loc             |     lr |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m |--------------------------------+----------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00000 | RUNNING  | 10.0.60.5:149   | 0.01   |      2 |          10.408  | 2000 | -1.60975 |              1.21608 |             -9.15675 |            26.4    |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00001 | RUNNING  | 10.0.41.148:770 | 0.0001 |      2 |          11.0711 | 2000 | -1.73855 |              1.15816 |             -7.46149 |            28.1549 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00002 | RUNNING  | 10.0.37.253:77  | 1e-06  |      2 |          10.5438 | 2000 | -1.26987 |              1.47919 |             -7.61559 |            23.9277 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00000:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 3000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-36\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 18.01\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.3782546164020593\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -0.7582845619825213\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -8.947227195316637\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 68\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 143\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: 92fec9273b2e46d1ad58bc09e3dc93ad\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 2512\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 0.01\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.6261216402053833\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: 0.5842635631561279\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: 0.5155238509178162\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: -0.12198610603809357\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.03604269027709961\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.014169871807098389\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.03604269027709961\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.034488677978515625\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.035999417304992676\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.03599202632904053\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.9870736002922058\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.046059370040893555\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.0461353063583374\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.035999417304992676\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.03604269027709961\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.5849756002426147\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.014169871807098389\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.0588455200195312\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.014169871807098389\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.38384008407592773\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.0486796498298645\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.03604269027709961\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.014395713806152344\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.4850192964076996\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.035999417304992676\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.034488677978515625\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.2326958179473877\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.014395713806152344\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.014169871807098389\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.014395713806152344\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.0461353063583374\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.7824806571006775\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.2202584743499756\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.046059370040893555\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.034488677978515625\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.014169871807098389\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 3000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 16032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 3000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 16032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 4\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 3\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.60.5\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 14.644444444444446\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.061111111111111116\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08694306930693069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 149\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06347353598448931\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.049444141529928126\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.693860311206868\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.18410930307618642\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 17.423094272613525\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.015077590942383\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 17.423094272613525\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 2315.364\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 13.821\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 37775.887\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.847\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928196\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 3000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 3\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00001:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 3000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-37\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 15.13\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.2926764030148967\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -0.44025530014110964\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -5.256030783267092\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 69\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 140\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: f3ef094fd1234ee5bedb38f5fd2ace46\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-3\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 2512\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 0.0001\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.8666979074478149\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: 0.7243526577949524\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: 0.360869824886322\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: 0.051149554550647736\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.06160050630569458\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.06162917613983154\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.016857892274856567\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.06162917613983154\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.06160050630569458\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.717406690120697\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.06162917613983154\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 3.415346145629883e-05\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.03260147571563721\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.21672415733337402\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.4775159955024719\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.03260147571563721\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.0881088376045227\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.06777215003967285\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.03260147571563721\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.076022207736969\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.0881088376045227\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.5680124759674072\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.03260147571563721\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.016857892274856567\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.03260147571563721\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.03260147571563721\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.076022207736969\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.06160050630569458\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.3262718915939331\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.016857892274856567\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.6574385166168213\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.37727129459381104\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.06162917613983154\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 3.415346145629883e-05\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.076022207736969\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.03260147571563721\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 3000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 16032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 3000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 16032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 4\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 3\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.41.148\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 15.044444444444444\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.060000000000000005\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08694306930693069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 770\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06548455411003681\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.05406219520325539\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.868250159199962\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.1919243005483826\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 18.310775995254517\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.239674091339111\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 18.310775995254517\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 3036.085\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 10.54\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 35534.597\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.901\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928197\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 3000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 3\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00001\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Current time: 2021-12-19 15:36:37 (running for 00:00:27.15)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Memory usage on this node: 3.7/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Resources requested: 3.0/35 CPUs, 3.0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result logdir: /domino/datasets/local/Ray_Quick_Start/DQN\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Number of trials: 3/3 (3 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | Trial name                     | status   | loc             |     lr |   iter |   total time (s) |   ts |    reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m |--------------------------------+----------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------|\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00000 | RUNNING  | 10.0.60.5:149   | 0.01   |      3 |          17.4231 | 3000 | -0.758285 |              1.37825 |             -8.94723 |            18.01   |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00001 | RUNNING  | 10.0.41.148:770 | 0.0001 |      3 |          18.3108 | 3000 | -0.440255 |              1.29268 |             -5.25603 |            15.13   |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00002 | RUNNING  | 10.0.37.253:77  | 1e-06  |      2 |          10.5438 | 2000 | -1.26987  |              1.47919 |             -7.61559 |            23.9277 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00002:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 3000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-37\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 18.53\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.4791933238366712\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -0.7039685438461002\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -7.6155857812863\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 65\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 148\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: 7aca033a6d2a4b5eb373ff4c3af579e8\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 2512\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 1.0e-06\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 2.3730099201202393e-05\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: -0.2489694207906723\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: -0.4023548364639282\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: -0.18651042878627777\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19843119382858276\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09976886212825775\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.7389272451400757\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.5349550247192383\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2512717545032501\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2512717545032501\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.25843706727027893\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.5142539739608765\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.25843706727027893\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.11012762784957886\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -2.304877758026123\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09976886212825775\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.25843706727027893\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.40554141998291016\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.40554141998291016\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.25843706727027893\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.40554141998291016\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.40554141998291016\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.7282907962799072\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19843119382858276\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09917369484901428\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09976886212825775\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2512717545032501\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.5236804485321045\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19843119382858276\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.9805357456207275\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19843119382858276\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.25843706727027893\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19843119382858276\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2512717545032501\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2512717545032501\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19843119382858276\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 3000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 16032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 3000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 16032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 4\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 3\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.37.253\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 14.900000000000002\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.05888888888888889\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08694306930693069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 77\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06516928912043632\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.052121388566267725\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.713439255271361\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.19348880289195047\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 17.81671166419983\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.272938966751099\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 17.81671166419983\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 3344.632\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 9.568\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 39979.068\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.8\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928197\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 3000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 3\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00002\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Current time: 2021-12-19 15:36:42 (running for 00:00:32.33)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Memory usage on this node: 3.7/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Resources requested: 3.0/35 CPUs, 3.0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result logdir: /domino/datasets/local/Ray_Quick_Start/DQN\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Number of trials: 3/3 (3 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | Trial name                     | status   | loc             |     lr |   iter |   total time (s) |   ts |    reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m |--------------------------------+----------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------|\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00000 | RUNNING  | 10.0.60.5:149   | 0.01   |      3 |          17.4231 | 3000 | -0.758285 |              1.37825 |             -8.94723 |              18.01 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00001 | RUNNING  | 10.0.41.148:770 | 0.0001 |      3 |          18.3108 | 3000 | -0.440255 |              1.29268 |             -5.25603 |              15.13 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00002 | RUNNING  | 10.0.37.253:77  | 1e-06  |      3 |          17.8167 | 3000 | -0.703969 |              1.47919 |             -7.61559 |              18.53 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00000:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 4000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-43\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 11.7\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.3803057687191043\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -0.12617446364028442\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -3.431882010059986\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 88\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 231\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: 92fec9273b2e46d1ad58bc09e3dc93ad\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 3520\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 0.01\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.7579535245895386\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: 0.6808334589004517\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: 0.5537849068641663\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: 0.08367976546287537\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.07030773162841797\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.0400882959365845\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.7080528736114502\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.054276734590530396\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19709718227386475\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1317422091960907\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.6790961027145386\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.07855105400085449\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19707119464874268\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.054276734590530396\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19709718227386475\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19709718227386475\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.07035475969314575\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.07855105400085449\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19707119464874268\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.054276734590530396\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19709718227386475\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.07855105400085449\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19707119464874268\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.07030773162841797\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1317422091960907\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1317422091960907\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.054276734590530396\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.8130505084991455\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19709718227386475\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.3234126567840576\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1970658302307129\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.054276734590530396\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19707119464874268\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.054276734590530396\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1970658302307129\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1317422091960907\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 4000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 24032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 4000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 24032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 6\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 4\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.60.5\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 15.166666666666666\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.05777777777777778\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08694306930693069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 149\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.0635165018019967\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.049520530681141484\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.695886201345301\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.189435220744656\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 24.575631618499756\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.1525373458862305\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 24.575631618499756\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 3297.433\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 9.705\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 40043.478\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.799\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928203\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 4000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 4\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00001:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 4000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-44\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 13.47\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.557984110299786\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -0.20933157689539925\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -5.177893571441768\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 76\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 216\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: f3ef094fd1234ee5bedb38f5fd2ace46\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-3\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 3520\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 0.0001\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.7745935320854187\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: 0.6886458992958069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: 0.4118369221687317\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: -0.03415939211845398\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0722399353981018\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.02889019250869751\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.08498713374137878\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0521199107170105\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0722399353981018\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0722399353981018\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0871630311012268\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.08498713374137878\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0871630311012268\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.0064666271209717\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.08498713374137878\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0521199107170105\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0871630311012268\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0521199107170105\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.1180827617645264\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.3468674123287201\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0521199107170105\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.1213456392288208\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0521199107170105\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0722399353981018\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0871630311012268\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.02062016725540161\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0871630311012268\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.43990084528923035\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.017748773097991943\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0871630311012268\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.565334141254425\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.096280574798584\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0722399353981018\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.08498713374137878\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0871630311012268\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0722399353981018\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 4000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 24032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 4000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 24032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 6\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 4\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.41.148\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 15.199999999999998\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.05333333333333334\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.222222222222221\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08694306930693069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 770\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06517873624129379\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.05365444100025151\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.8447957381633016\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.19386138276724263\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 25.750812530517578\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.4400365352630615\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 25.750812530517578\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 3102.848\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 10.313\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 38345.731\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.835\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928204\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 4000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 4\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00001\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00002:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 4000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-44\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 15.07\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.4587682693387154\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -0.3578078844696182\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -5.005827000467058\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 65\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 213\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: 7aca033a6d2a4b5eb373ff4c3af579e8\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 3520\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 1.0e-06\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: -0.0006053773686289787\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: -0.11406563967466354\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: -0.301289439201355\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: -0.13304194808006287\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.215814009308815\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.2902038097381592\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -2.0130162239074707\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18250396847724915\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.21903833746910095\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.21903833746910095\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.215814009308815\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09977499395608902\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.16407737135887146\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.048729419708252\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1871977150440216\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09977499395608902\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.017030924558639526\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1871977150440216\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.023384660482406616\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.023384660482406616\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.21903833746910095\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09977499395608902\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.215814009308815\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.21903833746910095\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.761395812034607\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.16407737135887146\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.017030924558639526\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09977499395608902\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.21903833746910095\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.215814009308815\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.06800037622451782\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.023384660482406616\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.215814009308815\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.21903833746910095\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.1801236867904663\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1871977150440216\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 4000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 24032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 4000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 24032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 6\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 4\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.37.253\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 15.011111111111111\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.05333333333333334\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08694306930693069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 77\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.0655408286349752\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.052417507607981105\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.703284628337504\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.1965407240159141\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 25.24660587310791\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.429894208908081\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 25.24660587310791\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 3080.854\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 10.387\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 38202.752\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.838\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928204\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 4000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 4\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00002\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Current time: 2021-12-19 15:36:47 (running for 00:00:37.75)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Memory usage on this node: 3.7/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Resources requested: 3.0/35 CPUs, 3.0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result logdir: /domino/datasets/local/Ray_Quick_Start/DQN\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Number of trials: 3/3 (3 RUNNING)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | Trial name                     | status   | loc             |     lr |   iter |   total time (s) |   ts |    reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m |--------------------------------+----------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------|\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00000 | RUNNING  | 10.0.60.5:149   | 0.01   |      4 |          24.5756 | 4000 | -0.126174 |              1.38031 |             -3.43188 |              11.7  |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00001 | RUNNING  | 10.0.41.148:770 | 0.0001 |      4 |          25.7508 | 4000 | -0.209332 |              1.55798 |             -5.17789 |              13.47 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00002 | RUNNING  | 10.0.37.253:77  | 1e-06  |      4 |          25.2466 | 4000 | -0.357808 |              1.45877 |             -5.00583 |              15.07 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+----------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00000:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 5000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-50\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 9.447619047619048\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.3976368654321498\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: 0.19838559591187185\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -1.835296538749103\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 105\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 336\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: 92fec9273b2e46d1ad58bc09e3dc93ad\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 4528\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 0.01\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.5968291163444519\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: 0.5534487962722778\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: 0.36677980422973633\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: -0.2052869349718094\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09975185990333557\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09973618388175964\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.3477773666381836\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.2000761032104492\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.9914761185646057\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.016103237867355347\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09973618388175964\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.1069960594177246\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.016103237867355347\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09973618388175964\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.06167927384376526\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09975185990333557\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09975185990333557\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.3255891799926758\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.3870928883552551\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09973618388175964\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09973618388175964\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09973618388175964\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09973856806755066\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.920617401599884\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.06168222427368164\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09973856806755066\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.6380701661109924\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.052531927824020386\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09975185990333557\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.06167927384376526\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09975185990333557\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09973618388175964\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.020951896905899048\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09973856806755066\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.06169959902763367\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09975185990333557\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 5000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 32032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 5000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 32032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 8\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 5\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.60.5\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 15.42222222222222\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.060000000000000005\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08694306930693069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 149\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06347688477746347\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.049591064453125\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.6948725645648457\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.19339632210886923\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 31.722071886062622\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.146440267562866\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 31.722071886062622\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 3290.521\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 9.725\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 39133.956\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.818\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928210\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 5000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 5\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00002:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 5000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-52\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 14.14\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.4587682693387154\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -0.3100748477040582\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -5.005827000467058\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 74\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 287\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: 7aca033a6d2a4b5eb373ff4c3af579e8\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 4528\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 1.0e-06\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.10394662618637085\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: 0.0036086945328861475\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: -0.20009392499923706\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: 0.014844533056020737\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18658041954040527\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09953456372022629\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09953456372022629\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.10871865600347519\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09953456372022629\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18658041954040527\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18812307715415955\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09953456372022629\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18812307715415955\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09953456372022629\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.05662737786769867\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19532188773155212\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09953456372022629\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.1280909776687622\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.1280909776687622\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.77363121509552\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.05662737786769867\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.1280909776687622\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18812307715415955\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18658041954040527\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09953456372022629\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18812307715415955\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18812307715415955\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.4320220649242401\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09953456372022629\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.07963497936725616\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18812307715415955\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.19532188773155212\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09953456372022629\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.07963497936725616\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18812307715415955\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.05662737786769867\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 5000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 32032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 5000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 32032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 8\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 5\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.37.253\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 15.42222222222222\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.05444444444444445\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08694306930693069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 77\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06550582207470786\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.05243989538936874\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.6984679312906548\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.1980242610716017\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 32.45991635322571\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.213310480117798\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 32.45991635322571\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 3354.211\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 9.54\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 39435.207\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.811\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928212\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 5000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 5\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00002\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00001:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 5000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-52\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 9.70873786407767\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.4309622624180274\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: 0.19272422074460377\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -2.345592268638887\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 103\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 319\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: f3ef094fd1234ee5bedb38f5fd2ace46\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-3\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 4528\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 0.0001\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.9264981746673584\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: 0.8151516914367676\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: 0.5216399431228638\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: -0.058001384139060974\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1309415102005005\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.07761037349700928\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.5800219774246216\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1309415102005005\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.11448776721954346\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1309415102005005\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.7314063310623169\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.0023890137672424316\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.012923836708068848\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.5039628744125366\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.3280411958694458\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0009655952453613281\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.4385504722595215\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.0009655952453613281\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.0023890137672424316\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.012923836708068848\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.012923836708068848\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1309415102005005\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.02519899606704712\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.024936199188232422\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.11448776721954346\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.012923836708068848\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.012923836708068848\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.8311671018600464\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.11448776721954346\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2669644355773926\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.5984247922897339\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.02519899606704712\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.012923836708068848\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.7521823644638062\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.907595157623291\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.012923836708068848\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 5000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 32032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 5000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 32032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 8\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 5\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.41.148\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 14.830000000000002\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.05499999999999999\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.239999999999998\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08694306930693067\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 770\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06502658170453311\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.053859333876632894\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.820340282224318\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.19907503217679226\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 33.204501152038574\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.453688621520996\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 33.204501152038574\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 2982.822\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 10.728\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 33657.086\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.951\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928212\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 5000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 5\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00001\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Current time: 2021-12-19 15:36:53 (running for 00:00:43.14)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Memory usage on this node: 3.7/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Resources requested: 1.0/35 CPUs, 1.0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result logdir: /domino/datasets/local/Ray_Quick_Start/DQN\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+------------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | Trial name                     | status     | loc             |     lr |   iter |   total time (s) |   ts |    reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m |--------------------------------+------------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------|\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00002 | RUNNING    | 10.0.37.253:77  | 1e-06  |      5 |          32.4599 | 5000 | -0.310075 |              1.45877 |             -5.00583 |           14.14    |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00000 | TERMINATED | 10.0.60.5:149   | 0.01   |      5 |          31.7221 | 5000 |  0.198386 |              1.39764 |             -1.8353  |            9.44762 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00001 | TERMINATED | 10.0.41.148:770 | 0.0001 |      5 |          33.2045 | 5000 |  0.192724 |              1.43096 |             -2.34559 |            9.70874 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+------------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Current time: 2021-12-19 15:36:58 (running for 00:00:48.15)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Memory usage on this node: 3.7/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Resources requested: 1.0/35 CPUs, 1.0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result logdir: /domino/datasets/local/Ray_Quick_Start/DQN\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+------------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | Trial name                     | status     | loc             |     lr |   iter |   total time (s) |   ts |    reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m |--------------------------------+------------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------|\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00002 | RUNNING    | 10.0.37.253:77  | 1e-06  |      5 |          32.4599 | 5000 | -0.310075 |              1.45877 |             -5.00583 |           14.14    |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00000 | TERMINATED | 10.0.60.5:149   | 0.01   |      5 |          31.7221 | 5000 |  0.198386 |              1.39764 |             -1.8353  |            9.44762 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00001 | TERMINATED | 10.0.41.148:770 | 0.0001 |      5 |          33.2045 | 5000 |  0.192724 |              1.43096 |             -2.34559 |            9.70874 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+------------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00002:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 6000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-36-59\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 13.9\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.4179330588448604\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -0.32403147087321016\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -3.1172022492598135\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 73\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 360\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: 7aca033a6d2a4b5eb373ff4c3af579e8\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 5536\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 1.0e-06\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.3024643063545227\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: 0.1281580626964569\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: -0.06972517818212509\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: -0.060173481702804565\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09924183785915375\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.10122601687908173\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.1668453961610794\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.15807926654815674\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1763630211353302\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.10122601687908173\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09924183785915375\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.20499590039253235\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.4867286682128906\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.3553411960601807\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.20270007848739624\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1763630211353302\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.20270007848739624\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09924183785915375\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.15807926654815674\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.20499590039253235\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1763630211353302\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.8394461274147034\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09924183785915375\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.20270007848739624\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.20270007848739624\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09924183785915375\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09924183785915375\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09924183785915375\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.10122601687908173\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09924183785915375\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.20499590039253235\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09924183785915375\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09924183785915375\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.44279950857162476\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.1668453961610794\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.20499590039253235\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 6000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 40032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 6000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 40032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 10\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 6\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.37.253\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 15.24\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.054000000000000006\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08694306930693067\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 77\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06542639666845028\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.05237098084450837\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.6905919785728463\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.19854340880050528\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 39.72224545478821\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.2623291015625\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 39.72224545478821\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 3146.78\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 10.169\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 36224.152\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.883\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928219\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 6000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 6\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00002\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Current time: 2021-12-19 15:37:03 (running for 00:00:53.40)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Memory usage on this node: 3.7/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Resources requested: 1.0/35 CPUs, 1.0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result logdir: /domino/datasets/local/Ray_Quick_Start/DQN\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+------------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | Trial name                     | status     | loc             |     lr |   iter |   total time (s) |   ts |    reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m |--------------------------------+------------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------|\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00002 | RUNNING    | 10.0.37.253:77  | 1e-06  |      6 |          39.7222 | 6000 | -0.324031 |              1.41793 |             -3.1172  |           13.9     |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00000 | TERMINATED | 10.0.60.5:149   | 0.01   |      5 |          31.7221 | 5000 |  0.198386 |              1.39764 |             -1.8353  |            9.44762 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00001 | TERMINATED | 10.0.41.148:770 | 0.0001 |      5 |          33.2045 | 5000 |  0.192724 |              1.43096 |             -2.34559 |            9.70874 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+------------+-----------------+--------+--------+------------------+------+-----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00002:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 7000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-37-06\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 11.87\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.4179330588448604\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: -0.03630488737103092\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -3.2942257275647506\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 83\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 443\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: 7aca033a6d2a4b5eb373ff4c3af579e8\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 6544\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 1.0e-06\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.4782913625240326\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: 0.2923518717288971\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: -0.008234652690589428\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: 0.08840496838092804\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18204578757286072\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18204578757286072\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.43174177408218384\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.2104950100183487\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.25592365860939026\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1253739297389984\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1516820788383484\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09931456297636032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.25592365860939026\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09931456297636032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18204578757286072\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.17598956823349\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.17598956823349\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1253739297389984\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09931456297636032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18204578757286072\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.17598956823349\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1253739297389984\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09931456297636032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.17057789862155914\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09931456297636032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.17598956823349\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18204578757286072\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18204578757286072\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.020874381065368652\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.25592365860939026\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.25592365860939026\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.35171741247177124\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1253739297389984\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18204578757286072\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1253739297389984\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.17598956823349\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 7000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 48032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 7000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 48032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 12\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 7\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.37.253\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 14.6\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.057499999999999996\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08694306930693069\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 77\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06520813379477296\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.052153738723295755\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.685674446165539\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.19919558437926818\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 46.770148515701294\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.047903060913086\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 46.770148515701294\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 3288.514\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 9.731\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 40209.026\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.796\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928226\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 7000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 7\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00002\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Current time: 2021-12-19 15:37:08 (running for 00:00:58.42)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Memory usage on this node: 3.7/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Resources requested: 1.0/35 CPUs, 1.0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result logdir: /domino/datasets/local/Ray_Quick_Start/DQN\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+------------+-----------------+--------+--------+------------------+------+------------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | Trial name                     | status     | loc             |     lr |   iter |   total time (s) |   ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m |--------------------------------+------------+-----------------+--------+--------+------------------+------+------------+----------------------+----------------------+--------------------|\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00002 | RUNNING    | 10.0.37.253:77  | 1e-06  |      7 |          46.7701 | 7000 | -0.0363049 |              1.41793 |             -3.29423 |           11.87    |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00000 | TERMINATED | 10.0.60.5:149   | 0.01   |      5 |          31.7221 | 5000 |  0.198386  |              1.39764 |             -1.8353  |            9.44762 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00001 | TERMINATED | 10.0.41.148:770 | 0.0001 |      5 |          33.2045 | 5000 |  0.192724  |              1.43096 |             -2.34559 |            9.70874 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+------------+-----------------+--------+--------+------------------+------+------------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Current time: 2021-12-19 15:37:13 (running for 00:01:03.47)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Memory usage on this node: 3.7/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Resources requested: 1.0/35 CPUs, 1.0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result logdir: /domino/datasets/local/Ray_Quick_Start/DQN\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Number of trials: 3/3 (1 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+------------+-----------------+--------+--------+------------------+------+------------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | Trial name                     | status     | loc             |     lr |   iter |   total time (s) |   ts |     reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m |--------------------------------+------------+-----------------+--------+--------+------------------+------+------------+----------------------+----------------------+--------------------|\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00002 | RUNNING    | 10.0.37.253:77  | 1e-06  |      7 |          46.7701 | 7000 | -0.0363049 |              1.41793 |             -3.29423 |           11.87    |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00000 | TERMINATED | 10.0.60.5:149   | 0.01   |      5 |          31.7221 | 5000 |  0.198386  |              1.39764 |             -1.8353  |            9.44762 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00001 | TERMINATED | 10.0.41.148:770 | 0.0001 |      5 |          33.2045 | 5000 |  0.192724  |              1.43096 |             -2.34559 |            9.70874 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+------------+-----------------+--------+--------+------------------+------+------------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result for DQN_SimpleCorridor_63f1b_00002:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   agent_timesteps_total: 8000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   custom_metrics: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   date: 2021-12-19_15-37-14\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_len_mean: 9.64423076923077\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_media: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_max: 1.4842968198194169\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_mean: 0.15804233503456278\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episode_reward_min: -3.587422726858536\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_this_iter: 104\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   episodes_total: 547\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   experiment_id: 7aca033a6d2a4b5eb373ff4c3af579e8\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   hostname: ray-61bf4c91992e0d71a81ef1b3-ray-worker-1\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   info:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     last_target_update_ts: 7552\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learner:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m       default_policy:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         learner_stats:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           cur_lr: 1.0e-06\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           max_q: 0.6373844146728516\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           mean_q: 0.3328273594379425\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m           min_q: -0.005020698998123407\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         mean_td_error: -0.06422799825668335\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         td_error:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09717443585395813\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1730821430683136\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.265756219625473\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09717443585395813\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.5655917525291443\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1003369688987732\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.23230493068695068\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18224945664405823\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09717443585395813\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.377961665391922\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.377961665391922\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1730821430683136\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.23230493068695068\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -1.2329788208007812\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1730821430683136\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.09717443585395813\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1730821430683136\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.377961665391922\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1003369688987732\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1003369688987732\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.377961665391922\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1730821430683136\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.18224945664405823\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.377961665391922\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.377961665391922\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.25556084513664246\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.377961665391922\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.5258746147155762\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.25556084513664246\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - 0.1003369688987732\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.3792804479598999\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m         - -0.1692456603050232\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_sampled: 8000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_agent_steps_trained: 56032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_sampled: 8000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained: 56032\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_steps_trained_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     num_target_updates: 14\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   iterations_since_restore: 8\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   node_ip: 10.0.37.253\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   num_healthy_workers: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   off_policy_estimator: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     cpu_util_percent: 15.150000000000002\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     gpu_util_percent0: 0.05500000000000001\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     ram_util_percent: 9.2\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     vram_util_percent0: 0.08694306930693067\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   pid: 77\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_max: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_mean: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   policy_reward_min: {}\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   sampler_perf:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_action_processing_ms: 0.06528759491382544\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_render_ms: 0.0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_env_wait_ms: 0.05227252105342912\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_inference_ms: 2.692388007229916\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     mean_raw_obs_processing_ms: 0.20167217032937104\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_since_restore: 54.16229557991028\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_this_iter_s: 7.392147064208984\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   time_total_s: 54.16229557991028\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timers:\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_throughput: 2092.212\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     learn_time_ms: 15.295\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_throughput: 36970.507\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m     load_time_ms: 0.866\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timestamp: 1639928234\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_this_iter: 0\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   timesteps_total: 8000\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   training_iteration: 8\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   trial_id: 63f1b_00002\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Current time: 2021-12-19 15:37:14 (running for 00:01:03.94)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Memory usage on this node: 3.7/60.0 GiB\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Resources requested: 0/35 CPUs, 0/5 GPUs, 0.0/186.81 GiB heap, 0.0/82.42 GiB objects (0.0/5.0 accelerator_type:V100)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Result logdir: /domino/datasets/local/Ray_Quick_Start/DQN\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m Number of trials: 3/3 (3 TERMINATED)\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+------------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | Trial name                     | status     | loc             |     lr |   iter |   total time (s) |   ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m |--------------------------------+------------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------|\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00000 | TERMINATED | 10.0.60.5:149   | 0.01   |      5 |          31.7221 | 5000 | 0.198386 |              1.39764 |             -1.8353  |            9.44762 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00001 | TERMINATED | 10.0.41.148:770 | 0.0001 |      5 |          33.2045 | 5000 | 0.192724 |              1.43096 |             -2.34559 |            9.70874 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m | DQN_SimpleCorridor_63f1b_00002 | TERMINATED | 10.0.37.253:77  | 1e-06  |      8 |          54.1623 | 8000 | 0.158042 |              1.4843  |             -3.58742 |            9.64423 |\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m +--------------------------------+------------+-----------------+--------+--------+------------------+------+----------+----------------------+----------------------+--------------------+\n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n",
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "best config:  {'env': <class '__main__.SimpleCorridor'>, 'env_config': {'corridor_length': 5}, 'num_gpus': 1, 'model': {'custom_model': 'my_model', 'vf_share_layers': True}, 'lr': 0.01, 'num_workers': 0, 'framework': 'torch', 'simple_optimizer': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run pid=887)\u001b[0m 2021-12-19 15:37:14,704\tINFO tune.py:626 -- Total run time: 64.47 seconds (63.89 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "## run and create the environment; change to work in a notebook\n",
    "\n",
    "import ray\n",
    "from ray.tune import grid_search\n",
    "import argparse\n",
    "import gym\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pprint as pp\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import grid_search\n",
    "from ray.rllib.env.env_context import EnvContext\n",
    "from ray.rllib.models import ModelCatalog\n",
    "from ray.rllib.models.tf.tf_modelv2 import TFModelV2\n",
    "from ray.rllib.models.tf.fcnet import FullyConnectedNetwork\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork as TorchFC\n",
    "from ray.rllib.utils.framework import try_import_tf, try_import_torch\n",
    "from ray.rllib.utils.test_utils import check_learning_achieved\n",
    "from ray.rllib.utils.numpy import convert_to_numpy\n",
    "\n",
    "local_dir = '/domino/datasets/local/{}'.format(os.environ['DOMINO_PROJECT_NAME'])\n",
    "\n",
    "# Can also register the env creator function explicitly with:\n",
    "#. register_env(\"corridor\", lambda config: SimpleCorridor(config))\n",
    "\n",
    "ModelCatalog.register_custom_model(\n",
    "    \"my_model\", TorchCustomModel\n",
    "    if framework == \"torch\" else CustomModel)\n",
    "\n",
    "config = {\n",
    "    \"env\": SimpleCorridor,  # or \"corridor\" if registered above\n",
    "    \"env_config\": {\n",
    "        \"corridor_length\": 5,\n",
    "    },\n",
    "    # Ray will automatically detect the number of gpus if set to 0\n",
    "    # Can be set manually if change '0' to and integer number below\n",
    "    # The number will be Workers/GPUs requested - 1\n",
    "    \"num_gpus\": 1,\n",
    "    \"model\": {\n",
    "        \"custom_model\": \"my_model\",\n",
    "        \"vf_share_layers\": True,\n",
    "    },\n",
    "    \"lr\": grid_search([1e-2, 1e-4, 1e-6]),  # try different lrs\n",
    "    \"num_workers\": 0,  # parallelism\n",
    "    \"framework\": framework,\n",
    "    'simple_optimizer': False\n",
    "}\n",
    "\n",
    "stop = {\n",
    "    \"training_iteration\": stop_iters,\n",
    "    \"timesteps_total\": stop_timesteps,\n",
    "    \"episode_reward_mean\": stop_reward,\n",
    "}\n",
    "\n",
    "results = tune.run(run, config=config, stop=stop, local_dir = local_dir)\n",
    "\n",
    "if as_test:\n",
    "    check_learning_achieved(results, stop_reward)\n",
    "    \n",
    "print(\"best config: \", results.get_best_config(metric = 'episode_reward_mean', mode = 'max'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note about Warnings\n",
    "\n",
    "Version 1.6 is validated on the latest edition of Domino, but you see here we chose to use the latest stable version of Ray, 1.9.  This version will occasionally throw some warning about depreciation for future versions of Ray or Pytorch because it is the newest stable version of Ray.  Don't worry too much about the warnings, they will not change the procedures followed to run the code.\n",
    "\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "*Using Pytorch and Ray for a simple finance example using DQN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
